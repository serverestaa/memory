{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8fdfc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from conformer_opt import ConformerWithFreq  \n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99944ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedEEGProcessor:\n",
    "    def __init__(self, base_path=None, data_ch_path=None, data_kr_path=None):\n",
    "        \"\"\"\n",
    "        Инициализирует расширенный обработчик данных ЭЭГ.\n",
    "        \n",
    "        Args:\n",
    "            base_path: Базовый путь к директории проекта\n",
    "            data_ch_path: Путь к китайским данным\n",
    "            data_kr_path: Путь к корейским данным\n",
    "        \"\"\"\n",
    "        self.base_path = base_path \n",
    "        self.data_ch_path = data_ch_path or os.path.join(self.base_path, 'Data_ch')\n",
    "        self.data_kr_path = data_kr_path or os.path.join(self.base_path, 'Data')\n",
    "        \n",
    "        # Настройка каналов ЭЭГ\n",
    "        self.ch_ch = list(range(63))        # Каналы для китайского набора\n",
    "        self.g_ch = list(range(61))         # Каналы для корейского набора\n",
    "        \n",
    "        # Каналы, которые нужно удалить\n",
    "        self.ch_rem = [0, 2, 6, 8, 29, 31, 51, 55]  # Для китайского набора\n",
    "        self.g_rem = [46, 49, 56, 58, 59, 60]       # Для корейского набора\n",
    "        \n",
    "        # Удаляем указанные каналы\n",
    "        for i in self.ch_rem:\n",
    "            if i in self.ch_ch:\n",
    "                self.ch_ch.remove(i)\n",
    "        for j in self.g_rem:\n",
    "            if j in self.g_ch:\n",
    "                self.g_ch.remove(j)\n",
    "        \n",
    "        # Списки для хранения данных\n",
    "        self.X_all = []\n",
    "        self.y_all = []\n",
    "        self.subjects_info = []  # Информация о субъектах\n",
    "        self.fs = 100  # Частота дискретизации (Гц)\n",
    "        \n",
    "        # Настройки фильтров\n",
    "        self.filter_settings = {\n",
    "            'bandpass': {'low': 0.5, 'high': 45.0},  # Полосовой фильтр (Гц)\n",
    "            'notch': 50.0,  # Режекторный фильтр (Гц)\n",
    "            'order': 4      # Порядок фильтра\n",
    "        }\n",
    "        \n",
    "        # Частотные диапазоны\n",
    "        self.bands = {\n",
    "            'delta': (0.5, 4),\n",
    "            'theta': (4, 8),\n",
    "            'alpha': (8, 13),\n",
    "            'beta': (13, 30),\n",
    "            'gamma': (30, 45)\n",
    "        }\n",
    "        \n",
    "    def load_chinese_data(self, condition=\"Ask\", max_subjects=9, custom_path=None):\n",
    "        \"\"\"Загружает китайские данные.\"\"\"\n",
    "        print(f\"Загрузка китайских данных ({condition})\")\n",
    "        \n",
    "        for subj in range(1, max_subjects + 1):\n",
    "            # Используем пользовательский путь, если указан\n",
    "            if custom_path:\n",
    "                file_path = f'{custom_path}/data_ch/{condition}/sbj_{subj}.mat'\n",
    "            else:\n",
    "                file_path = os.path.join(self.data_ch_path, f'{condition}/sbj_{subj}.mat')\n",
    "                \n",
    "            try:\n",
    "                print(f\"Загрузка файла: {file_path}\")\n",
    "                mat_data = loadmat(file_path)\n",
    "                \n",
    "                # Выбираем нужные каналы\n",
    "                X = np.array(mat_data['x_post'])[:-1, self.ch_ch, :]\n",
    "                y = np.array(mat_data['label_next_ind'])[0, :]\n",
    "                \n",
    "                # Транспонирование для получения формата (trials, channels, time)\n",
    "                X = np.transpose(X)\n",
    "                \n",
    "                self.X_all.append(X)\n",
    "                self.y_all.append(y)\n",
    "                self.subjects_info.append(f\"Chinese_{condition}_sbj_{subj}\")\n",
    "                \n",
    "                print(f\"  Форма данных X: {X.shape}, метки y: {y.shape}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при загрузке файла {file_path}: {e}\")\n",
    "    \n",
    "    def load_korean_data(self, condition=\"Ask\", max_subjects=14, custom_path=None):\n",
    "        \"\"\"Загружает корейские данные.\"\"\"\n",
    "        print(f\"Загрузка корейских данных ({condition})\")\n",
    "        \n",
    "        for subj in range(1, max_subjects + 1):\n",
    "            # Используем пользовательский путь, если указан\n",
    "            if custom_path:\n",
    "                file_path = f'{custom_path}/data/{condition}/sbj_{subj}.mat'\n",
    "            else:\n",
    "                file_path = os.path.join(self.data_kr_path, f'{condition}/sbj_{subj}.mat')\n",
    "                \n",
    "            try:\n",
    "                with h5py.File(file_path, 'r') as f:\n",
    "                    print(f\"Загрузка файла: {file_path}\")\n",
    "                    X = np.array(f['x_post'])[:, self.g_ch, :]\n",
    "                    y = np.array(f['label_next_ind'])[:, 0]\n",
    "                \n",
    "                self.X_all.append(X)\n",
    "                self.y_all.append(y)\n",
    "                self.subjects_info.append(f\"Korean_{condition}_sbj_{subj}\")\n",
    "                \n",
    "                print(f\"  Форма данных X: {X.shape}, метки y: {y.shape}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при загрузке файла {file_path}: {e}\")\n",
    "    \n",
    "    def apply_bandpass_filter(self, data):\n",
    "        \"\"\"Применяет полосовой фильтр к данным ЭЭГ.\"\"\"\n",
    "        low = self.filter_settings['bandpass']['low']\n",
    "        high = self.filter_settings['bandpass']['high']\n",
    "        order = self.filter_settings['order']\n",
    "        \n",
    "        # Создаем фильтр Баттерворта\n",
    "        b, a = signal.butter(order, [low/(self.fs/2), high/(self.fs/2)], btype='band')\n",
    "        \n",
    "        # Применяем фильтр ко всем каналам и испытаниям\n",
    "        filtered_data = np.zeros_like(data)\n",
    "        for i in range(data.shape[0]):\n",
    "            for j in range(data.shape[1]):\n",
    "                filtered_data[i, j, :] = signal.filtfilt(b, a, data[i, j, :])\n",
    "        \n",
    "        return filtered_data\n",
    "    \n",
    "    def apply_notch_filter(self, data):\n",
    "        \"\"\"Применяет режекторный фильтр для удаления сетевых наводок.\"\"\"\n",
    "        notch_freq = self.filter_settings['notch']\n",
    "        quality_factor = 30.0  # Добротность фильтра\n",
    "        \n",
    "        # Создаем режекторный фильтр\n",
    "        b, a = signal.iirnotch(notch_freq, quality_factor, self.fs)\n",
    "        \n",
    "        # Применяем фильтр ко всем каналам и испытаниям\n",
    "        filtered_data = np.zeros_like(data)\n",
    "        for i in range(data.shape[0]):\n",
    "            for j in range(data.shape[1]):\n",
    "                filtered_data[i, j, :] = signal.filtfilt(b, a, data[i, j, :])\n",
    "        \n",
    "        return filtered_data\n",
    "    \n",
    "    def extract_frequency_features(self, data):\n",
    "        \"\"\"Извлекает частотные признаки из данных ЭЭГ.\"\"\"\n",
    "        n_trials, n_channels, n_times = data.shape\n",
    "        n_bands = len(self.bands)\n",
    "        \n",
    "        # Создаем массив для хранения признаков\n",
    "        features = np.zeros((n_trials, n_channels * n_bands))\n",
    "        \n",
    "        # Вычисляем FFT для каждого испытания и канала\n",
    "        for i in range(n_trials):\n",
    "            for j in range(n_channels):\n",
    "                # Вычисляем спектр мощности\n",
    "                signal_fft = np.abs(np.fft.fft(data[i, j, :]))\n",
    "                signal_fft = signal_fft[:n_times//2]\n",
    "                \n",
    "                # Вычисляем частоты\n",
    "                freqs = np.fft.fftfreq(n_times, 1/self.fs)\n",
    "                freqs = freqs[:n_times//2]\n",
    "                \n",
    "                # Вычисляем мощность в каждом частотном диапазоне\n",
    "                for k, (band_name, (low, high)) in enumerate(self.bands.items()):\n",
    "                    # Находим индексы для текущего диапазона частот\n",
    "                    idx_band = np.logical_and(freqs >= low, freqs <= high)\n",
    "                    \n",
    "                    # Вычисляем среднюю мощность в диапазоне\n",
    "                    if np.any(idx_band):\n",
    "                        band_power = np.mean(signal_fft[idx_band])\n",
    "                    else:\n",
    "                        band_power = 0\n",
    "                    \n",
    "                    # Сохраняем признак\n",
    "                    features[i, j * n_bands + k] = band_power\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def normalize_per_subject(self, data_list, scaler_type='robust'):\n",
    "        \"\"\"Нормализует данные по каждому субъекту отдельно.\"\"\"\n",
    "        normalized_data_list = []\n",
    "        \n",
    "        for i, data in enumerate(data_list):\n",
    "            n_trials, n_channels, n_times = data.shape\n",
    "            \n",
    "            # Выбираем тип нормализации\n",
    "            if scaler_type == 'robust':\n",
    "                scaler = RobustScaler()\n",
    "            else:\n",
    "                scaler = StandardScaler()\n",
    "            \n",
    "            # Преобразуем данные для нормализации\n",
    "            data_flat = data.reshape(n_trials, -1)\n",
    "            \n",
    "            # Нормализуем данные\n",
    "            data_norm = scaler.fit_transform(data_flat)\n",
    "            \n",
    "            # Возвращаем исходную форму\n",
    "            data_norm = data_norm.reshape(n_trials, n_channels, n_times)\n",
    "            \n",
    "            normalized_data_list.append(data_norm)\n",
    "        \n",
    "        return normalized_data_list\n",
    "    \n",
    "    def preprocess_data_no_leakage(self, use_freq_features=True, normalize_subjects=True, \n",
    "                                balance_method='smote', apply_filters=True, \n",
    "                                test_size=0.3, val_size=0.15):\n",
    "        \n",
    "        \"\"\"Performs comprehensive EEG data preprocessing WITHOUT data leakage.\"\"\"\n",
    "        if not self.X_all:\n",
    "            raise ValueError(\"Data not loaded. Call load_all_data() first.\")\n",
    "        \n",
    "        # Step 1: Apply filters and normalization per subject (BEFORE any splitting)\n",
    "        X_list = [X.copy() for X in self.X_all]\n",
    "        y_list = [y.copy() for y in self.y_all]\n",
    "        \n",
    "        if apply_filters:\n",
    "            print(\"Applying filters...\")\n",
    "            for i in range(len(X_list)):\n",
    "                X_list[i] = self.apply_bandpass_filter(X_list[i])\n",
    "                X_list[i] = self.apply_notch_filter(X_list[i])\n",
    "        \n",
    "        if normalize_subjects:\n",
    "            print(\"Normalizing data per subject...\")\n",
    "            X_list = self.normalize_per_subject(X_list, scaler_type='robust')\n",
    "        \n",
    "        # Step 2: SUBJECT-LEVEL SPLIT (Critical fix)\n",
    "        print(\"Performing subject-level train/val/test split...\")\n",
    "        n_subjects = len(X_list)\n",
    "        subjects = list(range(n_subjects))\n",
    "        \n",
    "        # Split subjects, not trials\n",
    "        n_test_subjects = max(1, int(n_subjects * test_size))\n",
    "        n_val_subjects = max(1, int(n_subjects * val_size))\n",
    "        n_train_subjects = n_subjects - n_test_subjects - n_val_subjects\n",
    "        \n",
    "        # Randomly assign subjects to sets\n",
    "        np.random.seed(42)\n",
    "        np.random.shuffle(subjects)\n",
    "        \n",
    "        train_subjects = subjects[:n_train_subjects]\n",
    "        val_subjects = subjects[n_train_subjects:n_train_subjects + n_val_subjects]\n",
    "        test_subjects = subjects[n_train_subjects + n_val_subjects:]\n",
    "        \n",
    "        print(f\"Train subjects: {len(train_subjects)}, Val subjects: {len(val_subjects)}, Test subjects: {len(test_subjects)}\")\n",
    "        \n",
    "        # Separate data by subject assignment\n",
    "        X_train_list = [X_list[i] for i in train_subjects]\n",
    "        y_train_list = [y_list[i] for i in train_subjects]\n",
    "        \n",
    "        X_val_list = [X_list[i] for i in val_subjects]\n",
    "        y_val_list = [y_list[i] for i in val_subjects]\n",
    "        \n",
    "        X_test_list = [X_list[i] for i in test_subjects]\n",
    "        y_test_list = [y_list[i] for i in test_subjects]\n",
    "        \n",
    "        # Concatenate within each set\n",
    "        X_train = np.concatenate(X_train_list, axis=0)\n",
    "        y_train = np.concatenate(y_train_list, axis=0)\n",
    "        \n",
    "        X_val = np.concatenate(X_val_list, axis=0)\n",
    "        y_val = np.concatenate(y_val_list, axis=0)\n",
    "        \n",
    "        X_test = np.concatenate(X_test_list, axis=0)\n",
    "        y_test = np.concatenate(y_test_list, axis=0)\n",
    "        \n",
    "        print(f\"Train shape: {X_train.shape}, Val shape: {X_val.shape}, Test shape: {X_test.shape}\")\n",
    "        print(f\"Train classes: {np.bincount(y_train.astype(int))}\")\n",
    "        print(f\"Val classes: {np.bincount(y_val.astype(int))}\")\n",
    "        print(f\"Test classes: {np.bincount(y_test.astype(int))}\")\n",
    "        \n",
    "        # Step 3: Feature extraction (per set to avoid leakage)\n",
    "        if use_freq_features:\n",
    "            print(\"Extracting frequency features...\")\n",
    "            train_freq_features = self.extract_frequency_features(X_train)\n",
    "            val_freq_features = self.extract_frequency_features(X_val)\n",
    "            test_freq_features = self.extract_frequency_features(X_test)\n",
    "            \n",
    "            X_train_features = np.hstack([X_train.reshape(X_train.shape[0], -1), train_freq_features])\n",
    "            X_val_features = np.hstack([X_val.reshape(X_val.shape[0], -1), val_freq_features])\n",
    "            X_test_features = np.hstack([X_test.reshape(X_test.shape[0], -1), test_freq_features])\n",
    "        else:\n",
    "            X_train_features = X_train.reshape(X_train.shape[0], -1)\n",
    "            X_val_features = X_val.reshape(X_val.shape[0], -1)\n",
    "            X_test_features = X_test.reshape(X_test.shape[0], -1)\n",
    "        \n",
    "        # Step 4: Apply SMOTE ONLY to training set (Critical fix)\n",
    "        if balance_method == 'smote':\n",
    "            print(\"Applying SMOTE to training set only...\")\n",
    "            sampler = SMOTE(random_state=42)\n",
    "            X_train_balanced, y_train_balanced = sampler.fit_resample(X_train_features, y_train)\n",
    "            print(f\"Training set after SMOTE: {X_train_balanced.shape}\")\n",
    "            print(f\"Training classes after SMOTE: {np.bincount(y_train_balanced.astype(int))}\")\n",
    "        elif balance_method == 'undersample':\n",
    "            print(\"Applying undersampling to training set only...\")\n",
    "            sampler = RandomUnderSampler(random_state=42)\n",
    "            X_train_balanced, y_train_balanced = sampler.fit_resample(X_train_features, y_train)\n",
    "        else:\n",
    "            X_train_balanced = X_train_features\n",
    "            y_train_balanced = y_train\n",
    "        \n",
    "        # Validation and test sets remain unchanged\n",
    "        X_val_final = X_val_features\n",
    "        X_test_final = X_test_features\n",
    "        \n",
    "        # Restore 3D shape if not using frequency features\n",
    "        if not use_freq_features:\n",
    "            channels = X_train.shape[1]\n",
    "            timesteps = X_train.shape[2]\n",
    "            X_train_balanced = X_train_balanced.reshape(-1, channels, timesteps)\n",
    "            X_val_final = X_val_final.reshape(-1, channels, timesteps)\n",
    "            X_test_final = X_test_final.reshape(-1, channels, timesteps)\n",
    "        \n",
    "        return {\n",
    "            'X_train': X_train_balanced,\n",
    "            'y_train': y_train_balanced,\n",
    "            'X_val': X_val_final,\n",
    "            'y_val': y_val,\n",
    "            'X_test': X_test_final,\n",
    "            'y_test': y_test,\n",
    "            'train_subjects': train_subjects,\n",
    "            'val_subjects': val_subjects,\n",
    "            'test_subjects': test_subjects\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9248405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from conformer_opt import ConformerWithFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d9ffb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка китайских данных (Ask)\n",
      "Загрузка файла: C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_1.mat\n",
      "Ошибка при загрузке файла C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_1.mat: [Errno 2] No such file or directory: 'C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_1.mat'\n",
      "Загрузка файла: C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_2.mat\n",
      "Ошибка при загрузке файла C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_2.mat: [Errno 2] No such file or directory: 'C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_2.mat'\n",
      "Загрузка файла: C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_3.mat\n",
      "Ошибка при загрузке файла C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_3.mat: [Errno 2] No such file or directory: 'C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_3.mat'\n",
      "Загрузка файла: C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_4.mat\n",
      "Ошибка при загрузке файла C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_4.mat: [Errno 2] No such file or directory: 'C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_4.mat'\n",
      "Загрузка файла: C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_5.mat\n",
      "Ошибка при загрузке файла C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_5.mat: [Errno 2] No such file or directory: 'C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_5.mat'\n",
      "Загрузка файла: C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_6.mat\n",
      "Ошибка при загрузке файла C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_6.mat: [Errno 2] No such file or directory: 'C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_6.mat'\n",
      "Загрузка файла: C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_7.mat\n",
      "Ошибка при загрузке файла C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_7.mat: [Errno 2] No such file or directory: 'C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_7.mat'\n",
      "Загрузка файла: C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_8.mat\n",
      "Ошибка при загрузке файла C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_8.mat: [Errno 2] No such file or directory: 'C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_8.mat'\n",
      "Загрузка файла: C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_9.mat\n",
      "Ошибка при загрузке файла C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_9.mat: [Errno 2] No such file or directory: 'C:/Users/anurj/Desktop/RA-Fazli-BCI/data_ch/Ask/sbj_9.mat'\n",
      "Загрузка корейских данных (Ask)\n",
      "Ошибка при загрузке файла C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_1.mat: [Errno 2] Unable to synchronously open file (unable to open file: name = 'C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_1.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Ошибка при загрузке файла C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_2.mat: [Errno 2] Unable to synchronously open file (unable to open file: name = 'C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_2.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Ошибка при загрузке файла C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_3.mat: [Errno 2] Unable to synchronously open file (unable to open file: name = 'C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_3.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Ошибка при загрузке файла C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_4.mat: [Errno 2] Unable to synchronously open file (unable to open file: name = 'C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_4.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Ошибка при загрузке файла C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_5.mat: [Errno 2] Unable to synchronously open file (unable to open file: name = 'C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_5.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Ошибка при загрузке файла C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_6.mat: [Errno 2] Unable to synchronously open file (unable to open file: name = 'C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_6.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Ошибка при загрузке файла C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_7.mat: [Errno 2] Unable to synchronously open file (unable to open file: name = 'C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_7.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Ошибка при загрузке файла C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_8.mat: [Errno 2] Unable to synchronously open file (unable to open file: name = 'C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_8.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Ошибка при загрузке файла C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_9.mat: [Errno 2] Unable to synchronously open file (unable to open file: name = 'C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_9.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Ошибка при загрузке файла C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_10.mat: [Errno 2] Unable to synchronously open file (unable to open file: name = 'C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_10.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Ошибка при загрузке файла C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_11.mat: [Errno 2] Unable to synchronously open file (unable to open file: name = 'C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_11.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Ошибка при загрузке файла C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_12.mat: [Errno 2] Unable to synchronously open file (unable to open file: name = 'C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_12.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Ошибка при загрузке файла C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_13.mat: [Errno 2] Unable to synchronously open file (unable to open file: name = 'C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_13.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Ошибка при загрузке файла C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_14.mat: [Errno 2] Unable to synchronously open file (unable to open file: name = 'C:/Users/anurj/Desktop/RA-Fazli-BCI/data/Ask/sbj_14.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data not loaded. Call load_all_data() first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m processor.load_korean_data(condition=\u001b[33m\"\u001b[39m\u001b[33mAsk\u001b[39m\u001b[33m\"\u001b[39m, custom_path=custom_path)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 2) Preprocess raw EEG only—keep time‐series intact for Transformer (SMOTE version)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m processed_raw = \u001b[43mprocessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreprocess_data_no_leakage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_freq_features\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# ← keep shape (n_trials, n_ch, n_times)\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnormalize_subjects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbalance_method\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msmote\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# ← changed to 'smote'\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapply_filters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m X_train_raw = processed_raw[\u001b[33m'\u001b[39m\u001b[33mX_train\u001b[39m\u001b[33m'\u001b[39m]  \u001b[38;5;66;03m# shape: (N_train, n_ch, n_times)\u001b[39;00m\n\u001b[32m     21\u001b[39m y_train     = processed_raw[\u001b[33m'\u001b[39m\u001b[33my_train\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 210\u001b[39m, in \u001b[36mEnhancedEEGProcessor.preprocess_data_no_leakage\u001b[39m\u001b[34m(self, use_freq_features, normalize_subjects, balance_method, apply_filters, test_size, val_size)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Performs comprehensive EEG data preprocessing WITHOUT data leakage.\"\"\"\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.X_all:\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mData not loaded. Call load_all_data() first.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    212\u001b[39m \u001b[38;5;66;03m# Step 1: Apply filters and normalization per subject (BEFORE any splitting)\u001b[39;00m\n\u001b[32m    213\u001b[39m X_list = [X.copy() \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.X_all]\n",
      "\u001b[31mValueError\u001b[39m: Data not loaded. Call load_all_data() first."
     ]
    }
   ],
   "source": [
    "# ...existing code for EnhancedEEGProcessor...\n",
    "\n",
    "processor = EnhancedEEGProcessor(base_path='C:/Users/anurj/Desktop/RA-Fazli-BCI')\n",
    "\n",
    "custom_path = 'C:/Users/anurj/Desktop/RA-Fazli-BCI'\n",
    "\n",
    "processor.load_chinese_data(condition=\"Ask\", custom_path=custom_path)\n",
    "processor.load_korean_data(condition=\"Ask\", custom_path=custom_path)\n",
    "\n",
    "# 2) Preprocess raw EEG only—keep time‐series intact for Transformer (SMOTE version)\n",
    "processed_raw = processor.preprocess_data_no_leakage(\n",
    "    use_freq_features=False,    # ← keep shape (n_trials, n_ch, n_times)\n",
    "    normalize_subjects=True,\n",
    "    balance_method='smote',  # ← changed to 'smote'\n",
    "    apply_filters=True,\n",
    "    test_size=0.15,\n",
    "    val_size=0.15,\n",
    ")\n",
    "\n",
    "X_train_raw = processed_raw['X_train']  # shape: (N_train, n_ch, n_times)\n",
    "y_train     = processed_raw['y_train']\n",
    "X_val_raw   = processed_raw['X_val']    # shape: (N_val, n_ch, n_times)\n",
    "y_val       = processed_raw['y_val']\n",
    "X_test_raw  = processed_raw['X_test']   # shape: (N_test, n_ch, n_times)\n",
    "y_test      = processed_raw['y_test']\n",
    "\n",
    "# 3) Separately compute per‐channel band‐power for each set\n",
    "#    (n_bands = len(processor.bands) → 5 by default)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc28a725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_freq_tensors(X_raw_np):\n",
    "    \"\"\"\n",
    "    X_raw_np: NumPy array (n_trials, n_channels, n_times).\n",
    "    Returns: Tensor of shape (n_trials, n_channels, n_bands).\n",
    "    \"\"\"\n",
    "    # Use the same extract_frequency_features, then reshape:\n",
    "    flat = processor.extract_frequency_features(X_raw_np)\n",
    "    n_trials, flat_dim = flat.shape\n",
    "    n_ch    = X_raw_np.shape[1]\n",
    "    n_bands = flat_dim // n_ch\n",
    "    freq_np = flat.reshape(n_trials, n_ch, n_bands)\n",
    "    return torch.tensor(freq_np, dtype=torch.float32)\n",
    "\n",
    "X_train_freq = compute_freq_tensors(X_train_raw)  # → (N_train, n_ch, n_bands)\n",
    "X_val_freq   = compute_freq_tensors(X_val_raw)\n",
    "X_test_freq  = compute_freq_tensors(X_test_raw)\n",
    "\n",
    "# 4) Build PyTorch tensors for raw (time-domain)\n",
    "X_train_raw_t = torch.tensor(X_train_raw, dtype=torch.float32).unsqueeze(1)  # (N_train, 1, n_ch, n_times)\n",
    "X_val_raw_t   = torch.tensor(X_val_raw, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_raw_t  = torch.tensor(X_test_raw, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
    "y_val_t   = torch.tensor(y_val,   dtype=torch.long)\n",
    "y_test_t  = torch.tensor(y_test,  dtype=torch.long)\n",
    "\n",
    "# 5) Create a custom Dataset that returns (x_raw, x_freq, y)\n",
    "class EEGTimeFreqDataset(Dataset):\n",
    "    def __init__(self, X_raw, X_freq, y):\n",
    "        self.X_raw  = X_raw\n",
    "        self.X_freq = X_freq\n",
    "        self.y      = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_raw[idx], self.X_freq[idx], self.y[idx]\n",
    "\n",
    "train_dataset = EEGTimeFreqDataset(X_train_raw_t, X_train_freq, y_train_t)\n",
    "val_dataset   = EEGTimeFreqDataset(X_val_raw_t,   X_val_freq,   y_val_t)\n",
    "test_dataset  = EEGTimeFreqDataset(X_test_raw_t,  X_test_freq,  y_test_t)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=32, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False)\n",
    "\n",
    "# 6) Initialize ConformerWithFreq\n",
    "n_channels = X_train_raw.shape[1]       # e.g. 55\n",
    "n_times    = X_train_raw.shape[2]       # e.g. 100\n",
    "n_bands    = X_train_freq.shape[2]      # 5 by default\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ConformerWithFreq(\n",
    "    n_channels=n_channels,\n",
    "    n_times=n_times,\n",
    "    n_bands=n_bands,\n",
    "    emb_size=40,\n",
    "    depth=6,\n",
    "    n_classes=2,\n",
    "    dropout=0.5\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.5)\n",
    "\n",
    "# 7) Training loop\n",
    "num_epochs = 100\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for x_raw_batch, x_freq_batch, y_batch in train_loader:\n",
    "        x_raw_batch  = x_raw_batch.to(device)   # (B, 1, n_ch, n_times)\n",
    "        x_freq_batch = x_freq_batch.to(device)  # (B, n_ch, n_bands)\n",
    "        y_batch      = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x_raw_batch, x_freq_batch)  # (B, n_classes)\n",
    "        loss   = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total   = 0\n",
    "    with torch.no_grad():\n",
    "        for x_raw_batch, x_freq_batch, y_batch in val_loader:\n",
    "            x_raw_batch  = x_raw_batch.to(device)\n",
    "            x_freq_batch = x_freq_batch.to(device)\n",
    "            y_batch      = y_batch.to(device)\n",
    "\n",
    "            val_logits = model(x_raw_batch, x_freq_batch)\n",
    "            val_loss += criterion(val_logits, y_batch).item()\n",
    "\n",
    "            preds = val_logits.argmax(dim=1)\n",
    "            correct += (preds == y_batch).sum().item()\n",
    "            total   += y_batch.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_acc = correct / total\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_conformer_with_freq.pt\")\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f} | \"\n",
    "          f\"Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# 8) Test\n",
    "model.load_state_dict(torch.load(\"best_conformer_with_freq.pt\"))\n",
    "model.eval()\n",
    "\n",
    "all_preds  = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for x_raw_batch, x_freq_batch, y_batch in test_loader:\n",
    "        x_raw_batch  = x_raw_batch.to(device)\n",
    "        x_freq_batch = x_freq_batch.to(device)\n",
    "        y_batch      = y_batch.to(device)\n",
    "\n",
    "        out_logits = model(x_raw_batch, x_freq_batch)\n",
    "        preds = out_logits.argmax(dim=1).cpu().numpy()\n",
    "        labels = y_batch.cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(all_labels, all_preds))\n",
    "print(\"Classification Report:\", classification_report(all_labels, all_preds, target_names=[\"Class 0\", \"Class 1\"]))\n",
    "print(\"Confusion Matrix:\", confusion_matrix(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa1ce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(\"F1 Score:\", f1_score(all_labels, all_preds, average='weighted'))\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Forgotten', 'Remembered'],\n",
    "            yticklabels=['Forgotten', 'Remembered'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148107c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
