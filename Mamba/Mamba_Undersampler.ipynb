{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0DcgIBAPBS-",
        "outputId": "e6946ebe-f6f0-49b1-d53a-094588693a69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faM-T4pHQUNI",
        "outputId": "c6db1649-b1b2-4115-ccdb-793bdb122afd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Chinese subjects...\n",
            "Loading and processing Chinese subject 1...\n",
            "  Data shape: (996, 55, 100)\n",
            "  Applying spatial filter...\n",
            "  Applying bandpass filter...\n",
            "  Filtering trial 0/996\n",
            "  Applying memory normalization...\n",
            "  Normalizing trial 0/996\n",
            "Loading and processing Chinese subject 2...\n",
            "  Data shape: (884, 55, 100)\n",
            "  Applying spatial filter...\n",
            "  Applying bandpass filter...\n",
            "  Filtering trial 0/884\n",
            "  Applying memory normalization...\n",
            "  Normalizing trial 0/884\n",
            "Loading and processing Chinese subject 3...\n",
            "  Data shape: (1291, 55, 100)\n",
            "  Applying spatial filter...\n",
            "  Applying bandpass filter...\n",
            "  Filtering trial 0/1291\n",
            "  Filtering trial 1000/1291\n",
            "  Applying memory normalization...\n",
            "  Normalizing trial 0/1291\n",
            "  Normalizing trial 1000/1291\n",
            "Loading and processing Chinese subject 4...\n",
            "  Data shape: (908, 55, 100)\n",
            "  Applying spatial filter...\n",
            "  Applying bandpass filter...\n",
            "  Filtering trial 0/908\n",
            "  Applying memory normalization...\n",
            "  Normalizing trial 0/908\n",
            "Loading and processing Chinese subject 5...\n",
            "  Data shape: (882, 55, 100)\n",
            "  Applying spatial filter...\n",
            "  Applying bandpass filter...\n",
            "  Filtering trial 0/882\n",
            "  Applying memory normalization...\n",
            "  Normalizing trial 0/882\n",
            "Loading and processing Chinese subject 6...\n",
            "  Data shape: (904, 55, 100)\n",
            "  Applying spatial filter...\n",
            "  Applying bandpass filter...\n",
            "  Filtering trial 0/904\n",
            "  Applying memory normalization...\n",
            "  Normalizing trial 0/904\n",
            "Loading and processing Chinese subject 7...\n",
            "  Data shape: (942, 55, 100)\n",
            "  Applying spatial filter...\n",
            "  Applying bandpass filter...\n",
            "  Filtering trial 0/942\n",
            "  Applying memory normalization...\n",
            "  Normalizing trial 0/942\n",
            "Loading and processing Chinese subject 8...\n",
            "  Data shape: (1453, 55, 100)\n",
            "  Applying spatial filter...\n",
            "  Applying bandpass filter...\n",
            "  Filtering trial 0/1453\n",
            "  Filtering trial 1000/1453\n",
            "  Applying memory normalization...\n",
            "  Normalizing trial 0/1453\n",
            "  Normalizing trial 1000/1453\n",
            "Loading and processing Chinese subject 9...\n",
            "  Data shape: (1059, 55, 100)\n",
            "  Applying spatial filter...\n",
            "  Applying bandpass filter...\n",
            "  Filtering trial 0/1059\n",
            "  Filtering trial 1000/1059\n",
            "  Applying memory normalization...\n",
            "  Normalizing trial 0/1059\n",
            "  Normalizing trial 1000/1059\n",
            "Processing Korean subjects...\n",
            "Loading and processing Korean subject 1...\n",
            "  Data shape: (2536, 55, 100)\n",
            "  Applying spatial filter...\n",
            "  Applying bandpass filter...\n",
            "  Filtering trial 0/2536\n",
            "  Filtering trial 1000/2536\n",
            "  Filtering trial 2000/2536\n",
            "  Applying memory normalization...\n",
            "  Normalizing trial 0/2536\n",
            "  Normalizing trial 1000/2536\n",
            "  Normalizing trial 2000/2536\n",
            "Loading and processing Korean subject 2...\n",
            "  Data shape: (2873, 55, 100)\n",
            "  Applying spatial filter...\n",
            "  Applying bandpass filter...\n",
            "  Filtering trial 0/2873\n",
            "  Filtering trial 1000/2873\n",
            "  Filtering trial 2000/2873\n",
            "  Applying memory normalization...\n",
            "  Normalizing trial 0/2873\n",
            "  Normalizing trial 1000/2873\n",
            "  Normalizing trial 2000/2873\n",
            "Loading and processing Korean subject 3...\n",
            "  Data shape: (2486, 55, 100)\n",
            "  Applying spatial filter...\n",
            "  Applying bandpass filter...\n",
            "  Filtering trial 0/2486\n",
            "  Filtering trial 1000/2486\n",
            "  Filtering trial 2000/2486\n",
            "  Applying memory normalization...\n",
            "  Normalizing trial 0/2486\n",
            "  Normalizing trial 1000/2486\n",
            "  Normalizing trial 2000/2486\n",
            "Loading and processing Korean subject 4...\n",
            "  Data shape: (2660, 55, 100)\n",
            "  Applying spatial filter...\n",
            "  Applying bandpass filter...\n",
            "  Filtering trial 0/2660\n",
            "  Filtering trial 1000/2660\n",
            "  Filtering trial 2000/2660\n",
            "  Applying memory normalization...\n",
            "  Normalizing trial 0/2660\n",
            "  Normalizing trial 1000/2660\n",
            "  Normalizing trial 2000/2660\n",
            "Loading and processing Korean subject 5...\n",
            "  Data shape: (2180, 55, 100)\n",
            "  Applying spatial filter...\n",
            "  Applying bandpass filter...\n",
            "  Filtering trial 0/2180\n",
            "  Filtering trial 1000/2180\n",
            "  Filtering trial 2000/2180\n",
            "  Applying memory normalization...\n",
            "  Normalizing trial 0/2180\n",
            "  Normalizing trial 1000/2180\n",
            "  Normalizing trial 2000/2180\n",
            "Loading and processing Korean subject 6...\n",
            "  Data shape: (2805, 55, 100)\n",
            "  Applying spatial filter...\n",
            "  Applying bandpass filter...\n",
            "  Filtering trial 0/2805\n",
            "  Filtering trial 1000/2805\n",
            "  Filtering trial 2000/2805\n",
            "  Applying memory normalization...\n",
            "  Normalizing trial 0/2805\n",
            "  Normalizing trial 1000/2805\n",
            "  Normalizing trial 2000/2805\n",
            "Loading and processing Korean subject 7...\n",
            "  Data shape: (3606, 55, 100)\n",
            "  Applying spatial filter...\n",
            "  Applying bandpass filter...\n",
            "  Filtering trial 0/3606\n",
            "  Filtering trial 1000/3606\n",
            "  Filtering trial 2000/3606\n",
            "  Filtering trial 3000/3606\n",
            "  Applying memory normalization...\n",
            "  Normalizing trial 0/3606\n",
            "  Normalizing trial 1000/3606\n",
            "  Normalizing trial 2000/3606\n",
            "  Normalizing trial 3000/3606\n",
            "Loading and processing Korean subject 8...\n",
            "  Data shape: (2983, 55, 100)\n",
            "  Applying spatial filter...\n",
            "  Applying bandpass filter...\n",
            "  Filtering trial 0/2983\n",
            "  Filtering trial 1000/2983\n",
            "  Filtering trial 2000/2983\n",
            "  Applying memory normalization...\n",
            "  Normalizing trial 0/2983\n",
            "  Normalizing trial 1000/2983\n",
            "  Normalizing trial 2000/2983\n",
            "Loading and processing Korean subject 9...\n",
            "  Data shape: (2947, 55, 100)\n",
            "  Applying spatial filter...\n",
            "  Applying bandpass filter...\n",
            "  Filtering trial 0/2947\n",
            "  Filtering trial 1000/2947\n",
            "  Filtering trial 2000/2947\n",
            "  Applying memory normalization...\n",
            "  Normalizing trial 0/2947\n",
            "  Normalizing trial 1000/2947\n",
            "  Normalizing trial 2000/2947\n",
            "Loading and processing Korean subject 10...\n",
            "  Data shape: (3405, 55, 100)\n",
            "  Applying spatial filter...\n",
            "  Applying bandpass filter...\n",
            "  Filtering trial 0/3405\n",
            "  Filtering trial 1000/3405\n",
            "  Filtering trial 2000/3405\n",
            "  Filtering trial 3000/3405\n",
            "  Applying memory normalization...\n",
            "  Normalizing trial 0/3405\n",
            "  Normalizing trial 1000/3405\n",
            "  Normalizing trial 2000/3405\n",
            "  Normalizing trial 3000/3405\n",
            "Loading and processing Korean subject 11...\n",
            "  Data shape: (3008, 55, 100)\n",
            "  Applying spatial filter...\n",
            "  Applying bandpass filter...\n",
            "  Filtering trial 0/3008\n",
            "  Filtering trial 1000/3008\n",
            "  Filtering trial 2000/3008\n",
            "  Filtering trial 3000/3008\n",
            "  Applying memory normalization...\n",
            "  Normalizing trial 0/3008\n",
            "  Normalizing trial 1000/3008\n",
            "  Normalizing trial 2000/3008\n",
            "  Normalizing trial 3000/3008\n",
            "Loading and processing Korean subject 12...\n",
            "  Data shape: (3098, 55, 100)\n",
            "  Applying spatial filter...\n",
            "  Applying bandpass filter...\n",
            "  Filtering trial 0/3098\n",
            "  Filtering trial 1000/3098\n",
            "  Filtering trial 2000/3098\n",
            "  Filtering trial 3000/3098\n",
            "  Applying memory normalization...\n",
            "  Normalizing trial 0/3098\n",
            "  Normalizing trial 1000/3098\n",
            "  Normalizing trial 2000/3098\n",
            "  Normalizing trial 3000/3098\n",
            "Loading and processing Korean subject 13...\n",
            "  Data shape: (3897, 55, 100)\n",
            "  Applying spatial filter...\n",
            "  Applying bandpass filter...\n",
            "  Filtering trial 0/3897\n",
            "  Filtering trial 1000/3897\n",
            "  Filtering trial 2000/3897\n",
            "  Filtering trial 3000/3897\n",
            "  Applying memory normalization...\n",
            "  Normalizing trial 0/3897\n",
            "  Normalizing trial 1000/3897\n",
            "  Normalizing trial 2000/3897\n",
            "  Normalizing trial 3000/3897\n",
            "Loading and processing Korean subject 14...\n",
            "  Data shape: (2637, 55, 100)\n",
            "  Applying spatial filter...\n",
            "  Applying bandpass filter...\n",
            "  Filtering trial 0/2637\n",
            "  Filtering trial 1000/2637\n",
            "  Filtering trial 2000/2637\n",
            "  Applying memory normalization...\n",
            "  Normalizing trial 0/2637\n",
            "  Normalizing trial 1000/2637\n",
            "  Normalizing trial 2000/2637\n",
            "Combining all processed data...\n",
            "Shape of original data: (50440, 55, 100)\n",
            "Original label distribution: [32197 18243]\n",
            "\n",
            "--- Label distribution BEFORE balancing ---\n",
            "Training set: [19318 10946]\n",
            "Validation set: [6439 3649]\n",
            "Testing set: [6440 3648]\n",
            "\n",
            "Applying RandomUnderSampler to the training set...\n",
            "\n",
            "--- Final Data Distribution & Shapes ---\n",
            "Training set label distribution AFTER balancing: [10946 10946]\n",
            "Validation set label distribution (Unchanged): [6439 3649]\n",
            "Testing set label distribution (Unchanged): [6440 3648]\n",
            "\n",
            "Balanced training set shape: (21892, 55, 100)\n",
            "Validation set shape: (10088, 55, 100)\n",
            "Testing set shape: (10088, 55, 100)\n"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from scipy.io import loadmat\n",
        "from scipy import signal\n",
        "import gc  # Garbage collection\n",
        "\n",
        "def apply_spatial_filter(data):\n",
        "    \"\"\"Apply spatial filtering (CAR) efficiently\"\"\"\n",
        "    channel_mean = np.mean(data, axis=1, keepdims=True)\n",
        "    return data - channel_mean\n",
        "\n",
        "def apply_memory_normalization(data):\n",
        "    \"\"\"Apply optimal normalization for memory data\"\"\"\n",
        "    # Per-trial robust normalization to preserve memory-related amplitude differences\n",
        "    n_trials, n_channels, n_times = data.shape\n",
        "    normalized_data = np.zeros_like(data)\n",
        "\n",
        "    for i in range(n_trials):\n",
        "        if i % 1000 == 0:\n",
        "            print(f\"  Normalizing trial {i}/{n_trials}\")\n",
        "\n",
        "        trial_data = data[i]  # Shape: (channels, time)\n",
        "\n",
        "        # Robust normalization per trial (less sensitive to outliers than z-score)\n",
        "        trial_median = np.median(trial_data)\n",
        "        trial_mad = np.median(np.abs(trial_data - trial_median))  # Median Absolute Deviation\n",
        "\n",
        "        # Normalize: (data - median) / (1.4826 * MAD)\n",
        "        # 1.4826 makes MAD equivalent to std for normal distribution\n",
        "        if trial_mad > 0:\n",
        "            normalized_data[i] = (trial_data - trial_median) / (1.4826 * trial_mad)\n",
        "        else:\n",
        "            normalized_data[i] = trial_data - trial_median\n",
        "\n",
        "    return normalized_data\n",
        "\n",
        "def apply_bandpass_filter_safe(data, fs=100, low_freq=0.5, high_freq=45.0, order=4):\n",
        "    \"\"\"Apply bandpass filter with memory management\"\"\"\n",
        "    # Create filter coefficients\n",
        "    nyquist = fs / 2\n",
        "    low_norm = low_freq / nyquist\n",
        "    high_norm = high_freq / nyquist\n",
        "    b, a = signal.butter(order, [low_norm, high_norm], btype='band')\n",
        "\n",
        "    # Process trial by trial to save memory\n",
        "    n_trials, n_channels, n_times = data.shape\n",
        "    data_filtered = np.zeros_like(data, dtype=np.float32)  # Use float32 to save memory\n",
        "\n",
        "    for i in range(n_trials):\n",
        "        if i % 1000 == 0:\n",
        "            print(f\"  Filtering trial {i}/{n_trials}\")\n",
        "        data_filtered[i] = signal.filtfilt(b, a, data[i], axis=1)\n",
        "\n",
        "    return data_filtered\n",
        "\n",
        "# Setup channel lists\n",
        "ch_ch = list(range(63))\n",
        "g_ch = list(range(61))\n",
        "ch_rem = [0, 2, 6, 8, 29, 31, 51, 55]\n",
        "g_rem = [46, 49, 56, 58, 59, 60]\n",
        "\n",
        "for i in ch_rem:\n",
        "    ch_ch.remove(i)\n",
        "for j in g_rem:\n",
        "    g_ch.remove(j)\n",
        "\n",
        "# Process subjects one by one to manage memory\n",
        "processed_data = []\n",
        "processed_labels = []\n",
        "\n",
        "print(\"Processing Chinese subjects...\")\n",
        "for subj in range(1, 10):\n",
        "    file_path = f\"/content/drive/MyDrive/Colab_Notebooks/Ensemble_Adlet/data_ch/ASK/sbj_{subj}.mat\"\n",
        "    try:\n",
        "        print(f\"Loading and processing Chinese subject {subj}...\")\n",
        "        mat_data = loadmat(file_path)\n",
        "        X = np.array(mat_data['x_post'])[:-1, ch_ch, :].astype(np.float32)  # Use float32\n",
        "        y = np.array(mat_data['label_next_ind'])[0, :]\n",
        "        X = np.transpose(X)\n",
        "\n",
        "        print(f\"  Data shape: {X.shape}\")\n",
        "\n",
        "        # Apply spatial filtering\n",
        "        print(\"  Applying spatial filter...\")\n",
        "        X_spatial = apply_spatial_filter(X)\n",
        "\n",
        "        # Apply bandpass filtering\n",
        "        print(\"  Applying bandpass filter...\")\n",
        "        X_filtered = apply_bandpass_filter_safe(X_spatial)\n",
        "\n",
        "        # Apply memory-optimized normalization\n",
        "        print(\"  Applying memory normalization...\")\n",
        "        X_normalized = apply_memory_normalization(X_filtered)\n",
        "\n",
        "        processed_data.append(X_normalized)\n",
        "        processed_labels.append(y)\n",
        "\n",
        "        # Clean up memory\n",
        "        del X, X_spatial, X_filtered, X_normalized, mat_data\n",
        "        gc.collect()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading file {file_path}: {e}\")\n",
        "\n",
        "print(\"Processing Korean subjects...\")\n",
        "for subj in range(1, 15):\n",
        "    file_path = f'/content/drive/MyDrive/Colab_Notebooks/Ensemble_Adlet/data/ASK/sbj_{subj}.mat'\n",
        "    try:\n",
        "        print(f\"Loading and processing Korean subject {subj}...\")\n",
        "        with h5py.File(file_path, 'r') as f:\n",
        "            X = np.array(f['x_post'])[:, g_ch, :].astype(np.float32)  # Use float32\n",
        "            y = np.array(f['label_next_ind'])[:, 0]\n",
        "\n",
        "        print(f\"  Data shape: {X.shape}\")\n",
        "\n",
        "        # Apply spatial filtering\n",
        "        print(\"  Applying spatial filter...\")\n",
        "        X_spatial = apply_spatial_filter(X)\n",
        "\n",
        "        # Apply bandpass filtering\n",
        "        print(\"  Applying bandpass filter...\")\n",
        "        X_filtered = apply_bandpass_filter_safe(X_spatial)\n",
        "\n",
        "        # Apply memory-optimized normalization\n",
        "        print(\"  Applying memory normalization...\")\n",
        "        X_normalized = apply_memory_normalization(X_filtered)\n",
        "\n",
        "        processed_data.append(X_normalized)\n",
        "        processed_labels.append(y)\n",
        "\n",
        "        # Clean up memory\n",
        "        del X, X_spatial, X_filtered, X_normalized\n",
        "        gc.collect()\n",
        "\n",
        "    except OSError as e:\n",
        "        print(f\"Error loading file {file_path}: {e}\")\n",
        "\n",
        "# Now concatenate all processed data\n",
        "print(\"Combining all processed data...\")\n",
        "data = np.concatenate(processed_data, axis=0)\n",
        "labels = np.concatenate(processed_labels, axis=0)\n",
        "\n",
        "# Clean up\n",
        "del processed_data, processed_labels\n",
        "gc.collect()\n",
        "\n",
        "print(\"Shape of original data:\", data.shape)\n",
        "print(\"Original label distribution:\", np.bincount(labels.astype(int)))\n",
        "\n",
        "# --- Step 1: Split data BEFORE any resampling ---\n",
        "# First, split into training (80%) and a temporary set for validation/testing (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    data, labels, test_size=0.4, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "# Split the temporary set in half to get validation (10%) and test (10%) sets\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "# Clean up\n",
        "del data, X_temp, y_temp\n",
        "gc.collect()\n",
        "\n",
        "print(\"\\n--- Label distribution BEFORE balancing ---\")\n",
        "print(\"Training set:\", np.bincount(y_train.astype(int)))\n",
        "print(\"Validation set:\", np.bincount(y_val.astype(int)))\n",
        "print(\"Testing set:\", np.bincount(y_test.astype(int)))\n",
        "\n",
        "# --- Step 2: Apply RandomUnderSampler ONLY to the training data ---\n",
        "print(\"\\nApplying RandomUnderSampler to the training set...\")\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "\n",
        "# Reshape training data for the sampler (from 3D to 2D)\n",
        "train_shape = X_train.shape\n",
        "X_train_reshaped = X_train.reshape(train_shape[0], -1)\n",
        "\n",
        "X_train_resampled, y_train_resampled = rus.fit_resample(X_train_reshaped, y_train)\n",
        "\n",
        "# Reshape the balanced training data back to its original 3D format\n",
        "X_train_resampled = X_train_resampled.reshape(-1, train_shape[1], train_shape[2])\n",
        "\n",
        "print(\"\\n--- Final Data Distribution & Shapes ---\")\n",
        "print(\"Training set label distribution AFTER balancing:\", np.bincount(y_train_resampled.astype(int)))\n",
        "print(\"Validation set label distribution (Unchanged):\", np.bincount(y_val.astype(int)))\n",
        "print(\"Testing set label distribution (Unchanged):\", np.bincount(y_test.astype(int)))\n",
        "\n",
        "print(\"\\nBalanced training set shape:\", X_train_resampled.shape)\n",
        "print(\"Validation set shape:\", X_val.shape)\n",
        "print(\"Testing set shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ninja cmake\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install --no-build-isolation mamba-ssm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qh6trS4JLz6c",
        "outputId": "9624c5b6-5046-494b-c580-67a9501856f0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.12/dist-packages (3.31.6)\n",
            "Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/180.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.13.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting mamba-ssm\n",
            "  Downloading mamba_ssm-2.2.5.tar.gz (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.8/113.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from mamba-ssm) (2.8.0+cu126)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.12/dist-packages (from mamba-ssm) (3.4.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (from mamba-ssm) (1.13.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from mamba-ssm) (0.8.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from mamba-ssm) (4.56.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mamba-ssm) (25.0)\n",
            "Requirement already satisfied: setuptools>=61.0.0 in /usr/local/lib/python3.12/dist-packages (from mamba-ssm) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm) (1.11.1.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->mamba-ssm) (1.1.9)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->mamba-ssm) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->mamba-ssm) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->mamba-ssm) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->mamba-ssm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->mamba-ssm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->mamba-ssm) (2025.8.3)\n",
            "Building wheels for collected packages: mamba-ssm\n",
            "  Building wheel for mamba-ssm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mamba-ssm: filename=mamba_ssm-2.2.5-cp312-cp312-linux_x86_64.whl size=532566033 sha256=c8b65fcabfb49a94456c9971619007218e4073f19a84fb6b3894f33d43bee4a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/55/c4/85b634055d6a9b599d27f5cbeacf353c6c532d8e2d8769960b\n",
            "Successfully built mamba-ssm\n",
            "Installing collected packages: mamba-ssm\n",
            "Successfully installed mamba-ssm-2.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from mamba_ssm import Mamba\n",
        "\n",
        "class ConvEncoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, padding=0):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.norm = nn.BatchNorm1d(out_channels)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)  # [B, T, C] → [B, C, T]\n",
        "        x = self.conv(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.activation(x)\n",
        "        x = x.transpose(1, 2)  # [B, C, T] → [B, T, C]\n",
        "        return x\n",
        "\n",
        "\n",
        "class STMambaNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(STMambaNet, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = input_size\n",
        "\n",
        "        self.kernel_sizes = [5, 9]\n",
        "        self.conv_channels = [4, 4]\n",
        "\n",
        "        self.temp_convs = nn.ModuleList([\n",
        "            nn.Conv2d(in_channels=1, out_channels=out_ch, kernel_size=(1, k), padding=(0, k // 2))\n",
        "            for k, out_ch in zip(self.kernel_sizes, self.conv_channels)\n",
        "        ])\n",
        "\n",
        "        self.total_conv_channels = sum(self.conv_channels)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(self.total_conv_channels)\n",
        "        self.spatial_conv = nn.Conv2d(in_channels=self.total_conv_channels, out_channels=self.total_conv_channels, kernel_size=(1, 1))\n",
        "        self.batch_norm2 = nn.BatchNorm2d(self.total_conv_channels)\n",
        "        self.activation = nn.ELU()\n",
        "\n",
        "        self.var_pool = lambda x: torch.var(x, dim=1, keepdim=True)\n",
        "        self.avg_pool = lambda x: torch.mean(x, dim=1, keepdim=True)\n",
        "\n",
        "        self.norm_t = nn.LayerNorm(55)\n",
        "        self.norm_s = nn.LayerNorm(100)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        self.feedforward_1 = nn.Sequential(\n",
        "            nn.Linear(55, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 55)\n",
        "        )\n",
        "        self.feedforward_2 = nn.Sequential(\n",
        "            nn.Linear(100, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 100)\n",
        "        )\n",
        "\n",
        "        self.mamba_t = Mamba(d_model=55, d_state=8)\n",
        "        self.mamba_s = Mamba(d_model=100, d_state=8)\n",
        "\n",
        "        self.conv_t = ConvEncoder(in_channels=110, out_channels=55)\n",
        "        self.conv_s = ConvEncoder(in_channels=200, out_channels=100)\n",
        "\n",
        "        self.pool_t = nn.Identity()\n",
        "        self.pool_s = nn.Identity()\n",
        "\n",
        "        self.fc_s = nn.Linear(55*100, 32)\n",
        "        self.fc_t = nn.Linear(100 * 55, 32)\n",
        "\n",
        "        self.fc_class = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x, mode=\"classification\"):\n",
        "        x = x.unsqueeze(1)  # [B, 1, T, C]\n",
        "        x_convs = [conv(x) for conv in self.temp_convs]\n",
        "        x = torch.cat(x_convs, dim=1)  # [B, total_conv_channels, T, C]\n",
        "\n",
        "        x = self.batch_norm1(x)\n",
        "        x = self.spatial_conv(x)\n",
        "        x = self.batch_norm2(x)\n",
        "        x = self.activation(x)\n",
        "\n",
        "        x_var = self.var_pool(x)  # [B, 1, T, C]\n",
        "        x_avg = self.avg_pool(x)\n",
        "\n",
        "        x_var = x_var.permute(0, 2, 3, 1).squeeze(-1)  # [B, T, C]\n",
        "        x_avg = x_avg.permute(0, 2, 3, 1).squeeze(-1)\n",
        "\n",
        "        def shared_mamba_block(x, mamba, norm, feedforward):\n",
        "            res1 = x\n",
        "            x = norm(x)\n",
        "            x = mamba(x)\n",
        "            x = self.dropout(x) + res1\n",
        "            res2 = x\n",
        "            x = norm(x)\n",
        "            x = feedforward(x) + res2\n",
        "            return x\n",
        "\n",
        "        x_tvar = shared_mamba_block(x_var.permute(0, 2, 1), self.mamba_t, self.norm_t, self.feedforward_1)\n",
        "        x_tavg = shared_mamba_block(x_avg.permute(0, 2, 1), self.mamba_t, self.norm_t, self.feedforward_1)\n",
        "        x_t = torch.cat([x_tvar, x_tavg], dim=-1)  # [B, 55, 100] × 2 → [B, 110, 100]\n",
        "\n",
        "        x_svar = shared_mamba_block(x_var, self.mamba_s, self.norm_s, self.feedforward_2)\n",
        "        x_savg = shared_mamba_block(x_avg, self.mamba_s, self.norm_s, self.feedforward_2)\n",
        "        x_s = torch.cat([x_svar, x_savg], dim=-1)  # [B, T, 200]\n",
        "\n",
        "        x_tconv = self.conv_t(x_t)  # [B, 100, 55]\n",
        "        x_sconv = self.conv_s(x_s)  #[B,55,100]\n",
        "        x_sconv = x_sconv.permute(0, 2, 1)\n",
        "\n",
        "        x_tconv = self.pool_t(x_tconv).reshape(x_tconv.shape[0], -1)  # [B, 100 * 55]\n",
        "        x_sconv = self.pool_s(x_sconv).reshape(x_sconv.shape[0], -1)  # [B, 10 * 55 = 550]\n",
        "\n",
        "\n",
        "        x_sfc = self.fc_s(x_sconv)\n",
        "        x_tfc = self.fc_t(x_tconv)\n",
        "\n",
        "        x_fused = torch.cat([x_sfc, x_tfc], dim=1)  # [B, 64]\n",
        "\n",
        "        if mode == \"classification\":\n",
        "            return self.fc_class(x_fused)\n"
      ],
      "metadata": {
        "id": "_j5640_Fq_ag"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Training Hyperparameters\n",
        "batch_size = 32\n",
        "num_epochs_train = 30  # Classification\n",
        "learning_rate = 0.0001\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "# Data Preparation\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)  # (N_train, 55, 100)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "X_val_t = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_t = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "val_dataset = TensorDataset(X_val_t, y_val_t)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Model Init\n",
        "model = STMambaNet(input_size=100, hidden_size=128, num_classes=2)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Optimizer, Loss, Scheduler\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-3, weight_decay=1e-4)\n",
        "\n",
        "# Early Stopping Setup\n",
        "best_val_acc = 0\n",
        "patience = 10\n",
        "patience_counter = 0\n",
        "num_epochs = 30\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    model.train()\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    running_loss = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, mode=\"classification\")\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        train_correct += (preds == labels).sum().item()\n",
        "        train_total += labels.size(0)\n",
        "\n",
        "    train_acc = train_correct / train_total\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs, mode=\"classification\")\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            val_correct += (preds == labels).sum().item()\n",
        "            val_total += labels.size(0)\n",
        "\n",
        "    val_acc = val_correct / val_total\n",
        "\n",
        "    print(f\"Epoch {epoch}: Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | Loss: {running_loss:.4f}\")\n",
        "\n",
        "    # Early Stopping Check\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), \"best_model.pt\")  # Save best model\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= patience:\n",
        "        print(\"Early stopping triggered.\")\n",
        "        break\n",
        "\n",
        "# Load best model after training\n",
        "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "194ba2b9-1d5e-43d5-9f76-1e41a0463a0a",
        "id": "jgAl6_0GrGJf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc: 0.6243 | Val Acc: 0.6429 | Loss: 678.0808\n",
            "Epoch 2: Train Acc: 0.6516 | Val Acc: 0.6527 | Loss: 600.0732\n",
            "Epoch 3: Train Acc: 0.6607 | Val Acc: 0.6755 | Loss: 588.0272\n",
            "Epoch 4: Train Acc: 0.6679 | Val Acc: 0.6781 | Loss: 581.4468\n",
            "Epoch 5: Train Acc: 0.6690 | Val Acc: 0.6780 | Loss: 579.2857\n",
            "Epoch 6: Train Acc: 0.6738 | Val Acc: 0.6789 | Loss: 575.1247\n",
            "Epoch 7: Train Acc: 0.6738 | Val Acc: 0.6756 | Loss: 572.9868\n",
            "Epoch 8: Train Acc: 0.6716 | Val Acc: 0.6807 | Loss: 574.8981\n",
            "Epoch 9: Train Acc: 0.6742 | Val Acc: 0.6792 | Loss: 572.9644\n",
            "Epoch 10: Train Acc: 0.6757 | Val Acc: 0.6771 | Loss: 569.9468\n",
            "Epoch 11: Train Acc: 0.6780 | Val Acc: 0.6621 | Loss: 569.3362\n",
            "Epoch 12: Train Acc: 0.6755 | Val Acc: 0.6758 | Loss: 570.2716\n",
            "Epoch 13: Train Acc: 0.6790 | Val Acc: 0.6809 | Loss: 568.7279\n",
            "Epoch 14: Train Acc: 0.6783 | Val Acc: 0.6819 | Loss: 568.3108\n",
            "Epoch 15: Train Acc: 0.6771 | Val Acc: 0.6805 | Loss: 569.7628\n",
            "Epoch 16: Train Acc: 0.6753 | Val Acc: 0.6761 | Loss: 568.5722\n",
            "Epoch 17: Train Acc: 0.6787 | Val Acc: 0.6790 | Loss: 566.3182\n",
            "Epoch 18: Train Acc: 0.6800 | Val Acc: 0.6577 | Loss: 566.5647\n",
            "Epoch 19: Train Acc: 0.6791 | Val Acc: 0.6811 | Loss: 567.0401\n",
            "Epoch 20: Train Acc: 0.6791 | Val Acc: 0.6793 | Loss: 567.4370\n",
            "Epoch 21: Train Acc: 0.6780 | Val Acc: 0.6625 | Loss: 565.8417\n",
            "Epoch 22: Train Acc: 0.6814 | Val Acc: 0.6453 | Loss: 564.5606\n",
            "Epoch 23: Train Acc: 0.6795 | Val Acc: 0.6783 | Loss: 564.3223\n",
            "Epoch 24: Train Acc: 0.6802 | Val Acc: 0.6801 | Loss: 565.1544\n",
            "Early stopping triggered.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_t = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "test_dataset = TensorDataset(X_test_t, y_test_t)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "def evaluate_test(model, test_loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_test_batch, y_test_batch in test_loader:\n",
        "            X_test_batch, y_test_batch = X_test_batch.to(device), y_test_batch.to(device)\n",
        "\n",
        "            outputs = model(X_test_batch, mode=\"classification\")\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            correct += (preds == y_test_batch).sum().item()\n",
        "            total += y_test_batch.size(0)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(y_test_batch.cpu().numpy())\n",
        "\n",
        "    test_acc = correct / total\n",
        "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    cm_display = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    cm_display.plot(cmap=plt.cm.Blues)\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "evaluate_test(model, test_loader)\n"
      ],
      "metadata": {
        "outputId": "44867edd-3675-421f-a79e-31bc883b2d22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "GhhDuXnW7bnP"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.6742\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed version of the hyperparameter search with correct tensor shapes\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from mamba_ssm import Mamba\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "class FixedSTMambaNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes, config):\n",
        "        super(FixedSTMambaNet, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = input_size\n",
        "\n",
        "        # Use config parameters\n",
        "        conv_channels = config.get('conv_channels', [4, 4])\n",
        "        dropout_rate = config.get('dropout_rate', 0.3)\n",
        "        mamba_d_state = config.get('mamba_d_state', 8)\n",
        "\n",
        "        self.kernel_sizes = [5, 9]\n",
        "        self.conv_channels = conv_channels\n",
        "\n",
        "        # Temporal convolutions\n",
        "        self.temp_convs = nn.ModuleList([\n",
        "            nn.Conv2d(in_channels=1, out_channels=out_ch,\n",
        "                     kernel_size=(1, k), padding=(0, k // 2))\n",
        "            for k, out_ch in zip(self.kernel_sizes, self.conv_channels)\n",
        "        ])\n",
        "\n",
        "        self.total_conv_channels = sum(self.conv_channels)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(self.total_conv_channels)\n",
        "        self.spatial_conv = nn.Conv2d(in_channels=self.total_conv_channels,\n",
        "                                    out_channels=self.total_conv_channels,\n",
        "                                    kernel_size=(1, 1))\n",
        "        self.batch_norm2 = nn.BatchNorm2d(self.total_conv_channels)\n",
        "        self.activation = nn.ELU()\n",
        "\n",
        "        # Pooling operations\n",
        "        self.var_pool = lambda x: torch.var(x, dim=1, keepdim=True)\n",
        "        self.avg_pool = lambda x: torch.mean(x, dim=1, keepdim=True)\n",
        "\n",
        "        # Layer norms\n",
        "        self.norm_t = nn.LayerNorm(55)\n",
        "        self.norm_s = nn.LayerNorm(100)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "        # Feedforward networks\n",
        "        self.feedforward_1 = nn.Sequential(\n",
        "            nn.Linear(55, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 55)\n",
        "        )\n",
        "        self.feedforward_2 = nn.Sequential(\n",
        "            nn.Linear(100, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 100)\n",
        "        )\n",
        "\n",
        "        # Mamba layers with configurable d_state\n",
        "        self.mamba_t = Mamba(d_model=55, d_state=mamba_d_state)\n",
        "        self.mamba_s = Mamba(d_model=100, d_state=mamba_d_state)\n",
        "\n",
        "        # Add conv encoders to handle different channel sizes\n",
        "        self.conv_t = self._make_conv_encoder(110, 55)\n",
        "        self.conv_s = self._make_conv_encoder(200, 100)\n",
        "\n",
        "        # Identity pooling (keeping original behavior)\n",
        "        self.pool_t = nn.Identity()\n",
        "        self.pool_s = nn.Identity()\n",
        "\n",
        "        # FIXED: Properly calculate FC input sizes\n",
        "        # After processing, we get: temporal = (batch, 100, 55), spatial = (batch, 55, 100)\n",
        "        self.fc_s = nn.Linear(55 * 100, 32)  # spatial path: 55 channels × 100 time points\n",
        "        self.fc_t = nn.Linear(100 * 55, 32)  # temporal path: 100 time points × 55 channels\n",
        "\n",
        "        self.fc_class = nn.Linear(64, num_classes)\n",
        "\n",
        "    def _make_conv_encoder(self, in_channels, out_channels):\n",
        "        \"\"\"Create a simple conv encoder to match dimensions\"\"\"\n",
        "        return nn.Sequential(\n",
        "            nn.Conv1d(in_channels, out_channels, kernel_size=1),\n",
        "            nn.BatchNorm1d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x, mode=\"classification\"):\n",
        "        # Input: [batch, 55, 100]\n",
        "        x = x.unsqueeze(1)  # [batch, 1, 55, 100]\n",
        "\n",
        "        # Apply temporal convolutions\n",
        "        x_convs = [conv(x) for conv in self.temp_convs]  # List of [batch, conv_ch, 55, 100]\n",
        "        x = torch.cat(x_convs, dim=1)  # [batch, total_conv_channels, 55, 100]\n",
        "\n",
        "        # Batch norm and spatial conv\n",
        "        x = self.batch_norm1(x)\n",
        "        x = self.spatial_conv(x)\n",
        "        x = self.batch_norm2(x)\n",
        "        x = self.activation(x)\n",
        "\n",
        "        # Pooling over conv channels\n",
        "        x_var = self.var_pool(x)  # [batch, 1, 55, 100]\n",
        "        x_avg = self.avg_pool(x)  # [batch, 1, 55, 100]\n",
        "\n",
        "        # Remove channel dimension and prepare for Mamba\n",
        "        x_var = x_var.squeeze(1)  # [batch, 55, 100]\n",
        "        x_avg = x_avg.squeeze(1)  # [batch, 55, 100]\n",
        "\n",
        "        def shared_mamba_block(x, mamba, norm, feedforward):\n",
        "            res1 = x\n",
        "            x = norm(x)\n",
        "            x = mamba(x)\n",
        "            x = self.dropout(x) + res1\n",
        "            res2 = x\n",
        "            x = norm(x)\n",
        "            x = feedforward(x) + res2\n",
        "            return x\n",
        "\n",
        "        # Temporal path: process along channel dimension (55)\n",
        "        x_tvar = shared_mamba_block(x_var.permute(0, 2, 1), self.mamba_t,\n",
        "                                  self.norm_t, self.feedforward_1)  # [batch, 100, 55]\n",
        "        x_tavg = shared_mamba_block(x_avg.permute(0, 2, 1), self.mamba_t,\n",
        "                                  self.norm_t, self.feedforward_1)  # [batch, 100, 55]\n",
        "        x_t = torch.cat([x_tvar, x_tavg], dim=-1)  # [batch, 100, 110]\n",
        "\n",
        "        # Spatial path: process along time dimension (100)\n",
        "        x_svar = shared_mamba_block(x_var, self.mamba_s, self.norm_s, self.feedforward_2)  # [batch, 55, 100]\n",
        "        x_savg = shared_mamba_block(x_avg, self.mamba_s, self.norm_s, self.feedforward_2)  # [batch, 55, 100]\n",
        "        x_s = torch.cat([x_svar, x_savg], dim=-1)  # [batch, 55, 200]\n",
        "\n",
        "        # Apply conv encoders to reduce dimensions\n",
        "        x_tconv = self.conv_t(x_t.permute(0, 2, 1)).permute(0, 2, 1)  # [batch, 100, 55]\n",
        "        x_sconv = self.conv_s(x_s.permute(0, 2, 1)).permute(0, 2, 1)  # [batch, 55, 100]\n",
        "\n",
        "        # Apply pooling and flatten\n",
        "        x_tconv = self.pool_t(x_tconv).reshape(x_tconv.shape[0], -1)  # [batch, 100*55]\n",
        "        x_sconv = self.pool_s(x_sconv).reshape(x_sconv.shape[0], -1)  # [batch, 55*100]\n",
        "\n",
        "        # Fully connected layers\n",
        "        x_sfc = self.fc_s(x_sconv)  # [batch, 32]\n",
        "        x_tfc = self.fc_t(x_tconv)  # [batch, 32]\n",
        "\n",
        "        # Fusion and classification\n",
        "        x_fused = torch.cat([x_sfc, x_tfc], dim=1)  # [batch, 64]\n",
        "\n",
        "        if mode == \"classification\":\n",
        "            return self.fc_class(x_fused)\n",
        "\n",
        "class FixedHyperparameterSearchRunner:\n",
        "    def __init__(self, X_train, y_train, X_val, y_val, X_test, y_test,\n",
        "                 results_dir=\"hyperparameter_results\"):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_val = X_val\n",
        "        self.y_val = y_val\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "\n",
        "        # Setup results directory\n",
        "        self.results_dir = Path(results_dir)\n",
        "        self.results_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        # Results tracking\n",
        "        self.results = []\n",
        "        self.best_config = None\n",
        "        self.best_score = 0.0\n",
        "\n",
        "        # Device setup\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "    def create_optimizer(self, model, config):\n",
        "        \"\"\"Create optimizer based on config\"\"\"\n",
        "        lr = config.get('learning_rate', 1e-3)\n",
        "        weight_decay = config.get('weight_decay', 1e-4)\n",
        "        optimizer_type = config.get('optimizer_type', 'adam')\n",
        "\n",
        "        if optimizer_type == 'adam':\n",
        "            return optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "        elif optimizer_type == 'adamw':\n",
        "            return optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "        elif optimizer_type == 'sgd':\n",
        "            return optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay, momentum=0.9)\n",
        "        else:\n",
        "            return optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    def train_single_config(self, config, max_epochs=20):\n",
        "        \"\"\"Train model with a single configuration\"\"\"\n",
        "\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Training with config: {config}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        # Create data loaders\n",
        "        batch_size = config.get('batch_size', 32)\n",
        "\n",
        "        train_dataset = TensorDataset(\n",
        "            torch.tensor(self.X_train, dtype=torch.float32),\n",
        "            torch.tensor(self.y_train, dtype=torch.long)\n",
        "        )\n",
        "        val_dataset = TensorDataset(\n",
        "            torch.tensor(self.X_val, dtype=torch.float32),\n",
        "            torch.tensor(self.y_val, dtype=torch.long)\n",
        "        )\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        # Create model with fixed architecture\n",
        "        model = FixedSTMambaNet(\n",
        "            input_size=100,\n",
        "            hidden_size=config.get('hidden_size', 128),\n",
        "            num_classes=2,\n",
        "            config=config\n",
        "        )\n",
        "        model.to(self.device)\n",
        "\n",
        "        # Create optimizer and scheduler\n",
        "        optimizer = self.create_optimizer(model, config)\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer, mode='max', factor=0.5, patience=3, verbose=False\n",
        "        )\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Training loop\n",
        "        best_val_acc = 0\n",
        "        patience_counter = 0\n",
        "        patience = 7\n",
        "\n",
        "        for epoch in range(max_epochs):\n",
        "            # Training\n",
        "            model.train()\n",
        "            train_correct = 0\n",
        "            train_total = 0\n",
        "            running_loss = 0\n",
        "\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs, mode=\"classification\")\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "\n",
        "                # Gradient clipping\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                train_correct += (preds == labels).sum().item()\n",
        "                train_total += labels.size(0)\n",
        "\n",
        "            train_acc = train_correct / train_total\n",
        "\n",
        "            # Validation\n",
        "            model.eval()\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_loader:\n",
        "                    inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
        "                    outputs = model(inputs, mode=\"classification\")\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    val_correct += (preds == labels).sum().item()\n",
        "                    val_total += labels.size(0)\n",
        "\n",
        "            val_acc = val_correct / val_total\n",
        "\n",
        "            print(f\"Epoch {epoch+1:2d}: Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | Loss: {running_loss:.4f}\")\n",
        "\n",
        "            # Learning rate scheduling\n",
        "            scheduler.step(val_acc)\n",
        "\n",
        "            # Early stopping\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                patience_counter = 0\n",
        "                # Save best model\n",
        "                torch.save(model.state_dict(), self.results_dir / \"temp_best_model.pt\")\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        # Test evaluation with best model\n",
        "        model.load_state_dict(torch.load(self.results_dir / \"temp_best_model.pt\"))\n",
        "        model.eval()\n",
        "\n",
        "        test_dataset = TensorDataset(\n",
        "            torch.tensor(self.X_test, dtype=torch.float32),\n",
        "            torch.tensor(self.y_test, dtype=torch.long)\n",
        "        )\n",
        "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        test_correct = 0\n",
        "        test_total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
        "                outputs = model(inputs, mode=\"classification\")\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                test_correct += (preds == labels).sum().item()\n",
        "                test_total += labels.size(0)\n",
        "\n",
        "        test_acc = test_correct / test_total\n",
        "\n",
        "        results = {\n",
        "            'val_accuracy': best_val_acc,\n",
        "            'test_accuracy': test_acc,\n",
        "            'final_train_accuracy': train_acc,\n",
        "            'epochs_trained': epoch + 1\n",
        "        }\n",
        "\n",
        "        print(f\"✅ Results: Val Acc: {best_val_acc:.4f} | Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "        # Clean up\n",
        "        del model\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        return results\n",
        "\n",
        "    def run_search(self, search_configs, max_experiments=None, random_search=False):\n",
        "        \"\"\"Run hyperparameter search\"\"\"\n",
        "\n",
        "        import random as rnd\n",
        "        if random_search and max_experiments:\n",
        "            search_configs = rnd.sample(search_configs, min(max_experiments, len(search_configs)))\n",
        "        elif max_experiments:\n",
        "            search_configs = search_configs[:max_experiments]\n",
        "\n",
        "        print(f\"Running hyperparameter search with {len(search_configs)} configurations...\")\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        for i, config in enumerate(search_configs):\n",
        "            print(f\"\\n🔍 Experiment {i+1}/{len(search_configs)}\")\n",
        "\n",
        "            try:\n",
        "                # Train with this configuration\n",
        "                results = self.train_single_config(config)\n",
        "\n",
        "                # Store results\n",
        "                experiment_result = {\n",
        "                    'experiment_id': i,\n",
        "                    'config': config,\n",
        "                    'results': results,\n",
        "                    'timestamp': time.time()\n",
        "                }\n",
        "\n",
        "                self.results.append(experiment_result)\n",
        "\n",
        "                # Update best configuration\n",
        "                val_acc = results['val_accuracy']\n",
        "                if val_acc > self.best_score:\n",
        "                    self.best_score = val_acc\n",
        "                    self.best_config = config.copy()\n",
        "                    # Save best model permanently\n",
        "                    import shutil\n",
        "                    shutil.copy(\n",
        "                        self.results_dir / \"temp_best_model.pt\",\n",
        "                        self.results_dir / \"best_model.pt\"\n",
        "                    )\n",
        "\n",
        "                print(f\"✅ Completed experiment {i+1} | Val Acc: {val_acc:.4f} | Best so far: {self.best_score:.4f}\")\n",
        "\n",
        "                # Save intermediate results\n",
        "                self.save_results()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Experiment {i+1} failed: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                continue\n",
        "\n",
        "        total_time = time.time() - start_time\n",
        "        print(f\"\\n🏁 Search completed in {total_time/60:.1f} minutes\")\n",
        "        print(f\"🏆 Best validation accuracy: {self.best_score:.4f}\")\n",
        "        print(f\"🏆 Best configuration: {self.best_config}\")\n",
        "\n",
        "        return self.results\n",
        "\n",
        "    def save_results(self):\n",
        "        \"\"\"Save results to files\"\"\"\n",
        "        if not self.results:\n",
        "            return\n",
        "\n",
        "        # Save detailed results\n",
        "        with open(self.results_dir / \"search_results.json\", 'w') as f:\n",
        "            json.dump(self.results, f, indent=2)\n",
        "\n",
        "        # Save best config\n",
        "        with open(self.results_dir / \"best_config.json\", 'w') as f:\n",
        "            json.dump({\n",
        "                'best_score': self.best_score,\n",
        "                'best_config': self.best_config\n",
        "            }, f, indent=2)\n",
        "\n",
        "        # Create summary DataFrame\n",
        "        summary_data = []\n",
        "        for result in self.results:\n",
        "            row = result['config'].copy()\n",
        "            row.update(result['results'])\n",
        "            row['experiment_id'] = result['experiment_id']\n",
        "            summary_data.append(row)\n",
        "\n",
        "        df = pd.DataFrame(summary_data)\n",
        "        df.to_csv(self.results_dir / \"search_summary.csv\", index=False)\n",
        "\n",
        "        print(f\"📁 Results saved to {self.results_dir}\")\n",
        "\n",
        "# Safer configuration set (smaller changes from original)\n",
        "def create_safe_search_configs():\n",
        "    \"\"\"Create safer configurations that are closer to the original\"\"\"\n",
        "    return [\n",
        "        {\n",
        "            'learning_rate': 1e-3,      # 10x increase (conservative)\n",
        "            'mamba_d_state': 16,        # 2x increase\n",
        "            'dropout_rate': 0.2,        # Slight decrease\n",
        "            'batch_size': 64,           # 2x increase\n",
        "            'hidden_size': 128,         # Same\n",
        "            'conv_channels': [4, 4],    # Same as original\n",
        "            'weight_decay': 1e-4,       # Same\n",
        "        },\n",
        "        {\n",
        "            'learning_rate': 5e-4,      # 5x increase\n",
        "            'mamba_d_state': 16,        # 2x increase\n",
        "            'dropout_rate': 0.25,       # Slight decrease\n",
        "            'batch_size': 32,           # Same\n",
        "            'hidden_size': 128,         # Same\n",
        "            'conv_channels': [6, 6],    # Moderate increase\n",
        "            'weight_decay': 1e-4,       # Same\n",
        "        },\n",
        "        {\n",
        "            'learning_rate': 2e-3,      # 20x increase (aggressive)\n",
        "            'mamba_d_state': 8,         # Same\n",
        "            'dropout_rate': 0.1,        # Big decrease\n",
        "            'batch_size': 64,           # 2x increase\n",
        "            'hidden_size': 256,         # 2x increase\n",
        "            'conv_channels': [4, 4],    # Same\n",
        "            'weight_decay': 1e-3,       # 10x increase\n",
        "        }\n",
        "    ]\n",
        "\n",
        "print(\"✅ Fixed hyperparameter search runner ready!\")\n",
        "print(\"Run the cell below to start the search.\")"
      ],
      "metadata": {
        "id": "a5z9mRqfFg54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e9430e3-adfb-4685-a84b-3eb4f86266bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fixed hyperparameter search runner ready!\n",
            "Run the cell below to start the search.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell after copying the fixed code above\n",
        "\n",
        "# Initialize the FIXED search runner\n",
        "runner = FixedHyperparameterSearchRunner(\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    results_dir=\"eeg_hyperparameter_results_fixed\"\n",
        ")\n",
        "\n",
        "# Use safer configurations (smaller changes from original)\n",
        "print(\"🚀 Starting FIXED hyperparameter search with safer configurations...\")\n",
        "\n",
        "safe_configs = create_safe_search_configs()\n",
        "\n",
        "print(\"\\nConfigurations to test:\")\n",
        "for i, config in enumerate(safe_configs):\n",
        "    print(f\"Config {i+1}: LR={config['learning_rate']}, d_state={config['mamba_d_state']}, \"\n",
        "          f\"dropout={config['dropout_rate']}, batch={config['batch_size']}\")\n",
        "\n",
        "# Run the search\n",
        "results = runner.run_search(safe_configs)\n",
        "\n",
        "# Check results\n",
        "print(\"\\n📊 FINAL RESULTS:\")\n",
        "print(f\"Best validation accuracy: {runner.best_score:.4f}\")\n",
        "print(f\"Best configuration: {runner.best_config}\")\n",
        "\n",
        "# Display results if any succeeded\n",
        "if runner.results:\n",
        "    df = pd.read_csv(\"eeg_hyperparameter_results_fixed/search_summary.csv\")\n",
        "    print(\"\\n📈 All results:\")\n",
        "    print(df[['val_accuracy', 'test_accuracy', 'learning_rate', 'mamba_d_state', 'dropout_rate', 'batch_size']])\n",
        "else:\n",
        "    print(\"❌ No experiments succeeded. Check the error messages above.\")"
      ],
      "metadata": {
        "id": "QWi3sLUtFg20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c748250d-9a4c-45c8-bf85-33d916476135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "🚀 Starting FIXED hyperparameter search with safer configurations...\n",
            "\n",
            "Configurations to test:\n",
            "Config 1: LR=0.001, d_state=16, dropout=0.2, batch=64\n",
            "Config 2: LR=0.0005, d_state=16, dropout=0.25, batch=32\n",
            "Config 3: LR=0.002, d_state=8, dropout=0.1, batch=64\n",
            "Running hyperparameter search with 3 configurations...\n",
            "\n",
            "🔍 Experiment 1/3\n",
            "\n",
            "==================================================\n",
            "Training with config: {'learning_rate': 0.001, 'mamba_d_state': 16, 'dropout_rate': 0.2, 'batch_size': 64, 'hidden_size': 128, 'conv_channels': [4, 4], 'weight_decay': 0.0001}\n",
            "==================================================\n",
            "Epoch  1: Train Acc: 0.5448 | Val Acc: 0.5903 | Loss: 326.6547\n",
            "Epoch  2: Train Acc: 0.5927 | Val Acc: 0.6040 | Loss: 306.8947\n",
            "Epoch  3: Train Acc: 0.6158 | Val Acc: 0.6199 | Loss: 299.2024\n",
            "Epoch  4: Train Acc: 0.6266 | Val Acc: 0.6172 | Loss: 294.2930\n",
            "Epoch  5: Train Acc: 0.6385 | Val Acc: 0.6133 | Loss: 289.4210\n",
            "Epoch  6: Train Acc: 0.6527 | Val Acc: 0.6106 | Loss: 283.2629\n",
            "Epoch  7: Train Acc: 0.6697 | Val Acc: 0.5873 | Loss: 275.7833\n",
            "Epoch  8: Train Acc: 0.7120 | Val Acc: 0.6100 | Loss: 255.6236\n",
            "Epoch  9: Train Acc: 0.7398 | Val Acc: 0.5963 | Loss: 237.9264\n",
            "Epoch 10: Train Acc: 0.7637 | Val Acc: 0.6073 | Loss: 221.9207\n",
            "Early stopping at epoch 10\n",
            "✅ Results: Val Acc: 0.6199 | Test Acc: 0.6114\n",
            "✅ Completed experiment 1 | Val Acc: 0.6199 | Best so far: 0.6199\n",
            "📁 Results saved to eeg_hyperparameter_results_fixed\n",
            "\n",
            "🔍 Experiment 2/3\n",
            "\n",
            "==================================================\n",
            "Training with config: {'learning_rate': 0.0005, 'mamba_d_state': 16, 'dropout_rate': 0.25, 'batch_size': 32, 'hidden_size': 128, 'conv_channels': [6, 6], 'weight_decay': 0.0001}\n",
            "==================================================\n",
            "Epoch  1: Train Acc: 0.5665 | Val Acc: 0.5966 | Loss: 639.4688\n",
            "Epoch  2: Train Acc: 0.6134 | Val Acc: 0.6377 | Loss: 597.5911\n",
            "Epoch  3: Train Acc: 0.6319 | Val Acc: 0.6306 | Loss: 582.1992\n",
            "Epoch  4: Train Acc: 0.6464 | Val Acc: 0.6388 | Loss: 573.9705\n",
            "Epoch  5: Train Acc: 0.6534 | Val Acc: 0.6372 | Loss: 566.5780\n",
            "Epoch  6: Train Acc: 0.6643 | Val Acc: 0.6278 | Loss: 556.1444\n",
            "Epoch  7: Train Acc: 0.6796 | Val Acc: 0.6361 | Loss: 543.7978\n",
            "Epoch  8: Train Acc: 0.6979 | Val Acc: 0.6300 | Loss: 524.4862\n",
            "Epoch  9: Train Acc: 0.7307 | Val Acc: 0.6270 | Loss: 485.9522\n",
            "Epoch 10: Train Acc: 0.7538 | Val Acc: 0.6265 | Loss: 457.8411\n",
            "Epoch 11: Train Acc: 0.7726 | Val Acc: 0.6215 | Loss: 433.8111\n",
            "Early stopping at epoch 11\n",
            "✅ Results: Val Acc: 0.6388 | Test Acc: 0.6350\n",
            "✅ Completed experiment 2 | Val Acc: 0.6388 | Best so far: 0.6388\n",
            "📁 Results saved to eeg_hyperparameter_results_fixed\n",
            "\n",
            "🔍 Experiment 3/3\n",
            "\n",
            "==================================================\n",
            "Training with config: {'learning_rate': 0.002, 'mamba_d_state': 8, 'dropout_rate': 0.1, 'batch_size': 64, 'hidden_size': 256, 'conv_channels': [4, 4], 'weight_decay': 0.001}\n",
            "==================================================\n",
            "Epoch  1: Train Acc: 0.5504 | Val Acc: 0.5887 | Loss: 325.6152\n",
            "Epoch  2: Train Acc: 0.5983 | Val Acc: 0.5898 | Loss: 303.6353\n",
            "Epoch  3: Train Acc: 0.6068 | Val Acc: 0.5919 | Loss: 299.0707\n",
            "Epoch  4: Train Acc: 0.6153 | Val Acc: 0.5996 | Loss: 297.0427\n",
            "Epoch  5: Train Acc: 0.6205 | Val Acc: 0.6062 | Loss: 295.0733\n",
            "Epoch  6: Train Acc: 0.6227 | Val Acc: 0.6095 | Loss: 293.9723\n",
            "Epoch  7: Train Acc: 0.6252 | Val Acc: 0.6095 | Loss: 293.0706\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-3944764188>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Run the search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_configs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Check results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-1141126697>\u001b[0m in \u001b[0;36mrun_search\u001b[0;34m(self, search_configs, max_experiments, random_search)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0;31m# Train with this configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_single_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;31m# Store results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-1141126697>\u001b[0m in \u001b[0;36mtrain_single_config\u001b[0;34m(self, config, max_epochs)\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"classification\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;31m# Gradient clipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import random\n",
        "\n",
        "def create_grid_search_configs():\n",
        "    \"\"\"Create full grid search configurations\"\"\"\n",
        "    configs = {\n",
        "        'learning_rate': [5e-4, 1e-3, 2e-3],\n",
        "        'mamba_d_state': [8, 16, 32],\n",
        "        'dropout_rate': [0.1, 0.2, 0.3],\n",
        "        'batch_size': [32, 64],\n",
        "        'hidden_size': [128, 256],\n",
        "        'conv_channels': [[4, 4], [8, 8]],\n",
        "        'weight_decay': [1e-4, 1e-3],\n",
        "    }\n",
        "\n",
        "    keys = list(configs.keys())\n",
        "    values = list(configs.values())\n",
        "\n",
        "    search_space = []\n",
        "    for combination in itertools.product(*values):\n",
        "        config_dict = dict(zip(keys, combination))\n",
        "        search_space.append(config_dict)\n",
        "\n",
        "    return search_space\n",
        "\n",
        "def create_reduced_grid_search():\n",
        "    \"\"\"Create a smaller, more focused grid search\"\"\"\n",
        "    configs = {\n",
        "        'learning_rate': [1e-3, 2e-3],           # Focus on higher LR\n",
        "        'mamba_d_state': [16, 32],               # Skip smallest\n",
        "        'dropout_rate': [0.1, 0.2],              # Skip highest\n",
        "        'batch_size': [64],                      # Fix at 64\n",
        "        'hidden_size': [128, 256],               # Keep both\n",
        "        'conv_channels': [[4, 4], [8, 8]],       # Keep both\n",
        "        'weight_decay': [1e-4],                  # Fix weight decay\n",
        "    }\n",
        "\n",
        "    keys = list(configs.keys())\n",
        "    values = list(configs.values())\n",
        "\n",
        "    search_space = []\n",
        "    for combination in itertools.product(*values):\n",
        "        config_dict = dict(zip(keys, combination))\n",
        "        search_space.append(config_dict)\n",
        "\n",
        "    return search_space\n",
        "\n",
        "# OPTION 1: Full grid search (432 configs - takes 15-30 hours)\n",
        "print(\"🔍 OPTION 1: Full Grid Search\")\n",
        "full_grid_configs = create_grid_search_configs()\n",
        "print(f\"Total configurations: {len(full_grid_configs)}\")\n",
        "print(f\"Estimated time: {len(full_grid_configs) * 3} minutes = {len(full_grid_configs) * 3 / 60:.1f} hours\")\n",
        "\n",
        "# OPTION 2: Reduced grid search (16 configs - takes 1-2 hours)\n",
        "print(\"\\n🎯 OPTION 2: Reduced Grid Search (Recommended)\")\n",
        "reduced_grid_configs = create_reduced_grid_search()\n",
        "print(f\"Total configurations: {len(reduced_grid_configs)}\")\n",
        "print(f\"Estimated time: {len(reduced_grid_configs) * 3} minutes = {len(reduced_grid_configs) * 3 / 60:.1f} hours\")\n",
        "\n",
        "# OPTION 3: Random sample from full grid (20 configs - takes 1 hour)\n",
        "print(\"\\n🎲 OPTION 3: Random Sample from Full Grid\")\n",
        "random_sample_size = 20\n",
        "random_configs = random.sample(full_grid_configs, random_sample_size)\n",
        "print(f\"Total configurations: {len(random_configs)}\")\n",
        "print(f\"Estimated time: {len(random_configs) * 3} minutes = {len(random_configs) * 3 / 60:.1f} hours\")\n",
        "\n",
        "# Show sample configurations\n",
        "print(\"\\n📋 Sample configurations from reduced grid:\")\n",
        "for i, config in enumerate(reduced_grid_configs[:3]):\n",
        "    print(f\"Config {i+1}: {config}\")"
      ],
      "metadata": {
        "id": "ieXGqSb1Fi5Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cae36ca-6550-404d-88b9-55bee11a08e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 OPTION 1: Full Grid Search\n",
            "Total configurations: 432\n",
            "Estimated time: 1296 minutes = 21.6 hours\n",
            "\n",
            "🎯 OPTION 2: Reduced Grid Search (Recommended)\n",
            "Total configurations: 32\n",
            "Estimated time: 96 minutes = 1.6 hours\n",
            "\n",
            "🎲 OPTION 3: Random Sample from Full Grid\n",
            "Total configurations: 20\n",
            "Estimated time: 60 minutes = 1.0 hours\n",
            "\n",
            "📋 Sample configurations from reduced grid:\n",
            "Config 1: {'learning_rate': 0.001, 'mamba_d_state': 16, 'dropout_rate': 0.1, 'batch_size': 64, 'hidden_size': 128, 'conv_channels': [4, 4], 'weight_decay': 0.0001}\n",
            "Config 2: {'learning_rate': 0.001, 'mamba_d_state': 16, 'dropout_rate': 0.1, 'batch_size': 64, 'hidden_size': 128, 'conv_channels': [8, 8], 'weight_decay': 0.0001}\n",
            "Config 3: {'learning_rate': 0.001, 'mamba_d_state': 16, 'dropout_rate': 0.1, 'batch_size': 64, 'hidden_size': 256, 'conv_channels': [4, 4], 'weight_decay': 0.0001}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CHOOSE ONE OF THESE OPTIONS TO RUN:\n",
        "\n",
        "# Make sure you have the FixedHyperparameterSearchRunner from the previous cell\n",
        "\n",
        "# ============================================================================\n",
        "# OPTION 1: QUICK REDUCED GRID SEARCH (Recommended to start)\n",
        "# Time: 1-2 hours, 16 experiments\n",
        "# ============================================================================\n",
        "\n",
        "print(\"🎯 Running REDUCED GRID SEARCH (16 configs)\")\n",
        "configs = create_reduced_grid_search()\n",
        "\n",
        "runner = FixedHyperparameterSearchRunner(\n",
        "    X_train, y_train, X_val, y_val, X_test, y_test,\n",
        "    results_dir=\"grid_search_reduced\"\n",
        ")\n",
        "\n",
        "results = runner.run_search(configs)\n",
        "print(f\"\\n🏆 Best from reduced grid: {runner.best_score:.4f}\")"
      ],
      "metadata": {
        "id": "X2jm-at2N1ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# OPTION 2: RANDOM SAMPLE FROM FULL GRID\n",
        "# Time: 1 hour, 20 experiments\n",
        "# ============================================================================\n",
        "\n",
        "print(\"🎲 Running RANDOM SAMPLE from full grid (20 configs)\")\n",
        "full_configs = create_grid_search_configs()\n",
        "\n",
        "runner = FixedHyperparameterSearchRunner(\n",
        "    X_train, y_train, X_val, y_val, X_test, y_test,\n",
        "    results_dir=\"grid_search_random\"\n",
        ")\n",
        "\n",
        "results = runner.run_search(full_configs, max_experiments=20, random_search=True)\n",
        "print(f\"\\n🏆 Best from random sample: {runner.best_score:.4f}\")\n"
      ],
      "metadata": {
        "id": "HgtODvJ2miU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# OPTION 3: FULL GRID SEARCH (Run overnight!)\n",
        "# Time: 15-30 hours, 432 experiments\n",
        "# ============================================================================\n",
        "\n",
        "print(\"🔍 Running FULL GRID SEARCH (432 configs) - This will take 15-30 hours!\")\n",
        "full_configs = create_grid_search_configs()\n",
        "\n",
        "runner = FixedHyperparameterSearchRunner(\n",
        "    X_train, y_train, X_val, y_val, X_test, y_test,\n",
        "    results_dir=\"grid_search_full\"\n",
        ")\n",
        "\n",
        "results = runner.run_search(full_configs)\n",
        "print(f\"\\n🏆 Best from full grid: {runner.best_score:.4f}\")\n"
      ],
      "metadata": {
        "id": "5LNlVlk0mlze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# OPTION 4: SMART PROGRESSIVE SEARCH\n",
        "# Start small, then expand based on results\n",
        "# ============================================================================\n",
        "\n",
        "print(\"🧠 Running SMART PROGRESSIVE SEARCH\")\n",
        "\n",
        "# Step 1: Test a few promising configs\n",
        "safe_configs = create_safe_search_configs()\n",
        "runner.run_search(safe_configs)\n",
        "best_safe = runner.best_score\n",
        "\n",
        "# Step 2: If improvement, run reduced grid\n",
        "if best_safe > 0.63:\n",
        "    print(f\"✅ Safe configs achieved {best_safe:.3f}, running reduced grid...\")\n",
        "    reduced_configs = create_reduced_grid_search()\n",
        "    runner.run_search(reduced_configs)\n",
        "    best_reduced = runner.best_score\n",
        "\n",
        "    # Step 3: If still improving, run random sample\n",
        "    if best_reduced > 0.65:\n",
        "        print(f\"✅ Reduced grid achieved {best_reduced:.3f}, running random sample...\")\n",
        "        full_configs = create_grid_search_configs()\n",
        "        runner.run_search(full_configs, max_experiments=50, random_search=True)\n",
        "\n",
        "print(\"\\n📊 FINAL RESULTS:\")\n",
        "print(f\"Best validation accuracy: {runner.best_score:.4f}\")\n",
        "print(f\"Best test accuracy: {[r['results']['test_accuracy'] for r in runner.results if r['results']['val_accuracy'] == runner.best_score][0]:.4f}\")\n",
        "print(f\"Best configuration: {runner.best_config}\")\n",
        "\n",
        "# Analyze results\n",
        "if runner.results:\n",
        "    import pandas as pd\n",
        "    df = pd.read_csv(f\"{runner.results_dir}/search_summary.csv\")\n",
        "\n",
        "    print(f\"\\n📈 TOP 5 CONFIGURATIONS:\")\n",
        "    top_5 = df.nlargest(5, 'val_accuracy')\n",
        "    print(top_5[['val_accuracy', 'test_accuracy', 'learning_rate', 'mamba_d_state', 'dropout_rate', 'batch_size']])\n",
        "\n",
        "    print(f\"\\n📊 ANALYSIS:\")\n",
        "    print(f\"Learning rate - Best performers: {top_5['learning_rate'].value_counts().head(3).to_dict()}\")\n",
        "    print(f\"Mamba d_state - Best performers: {top_5['mamba_d_state'].value_counts().head(3).to_dict()}\")\n",
        "    print(f\"Dropout rate - Best performers: {top_5['dropout_rate'].value_counts().head(3).to_dict()}\")\n",
        "\n",
        "    # Find improvement over baseline\n",
        "    baseline_acc = 0.6443  # Your original accuracy\n",
        "    best_acc = runner.best_score\n",
        "    improvement = (best_acc - baseline_acc) / baseline_acc * 100\n",
        "    print(f\"\\n🚀 IMPROVEMENT: {improvement:+.1f}% over baseline ({baseline_acc:.4f} → {best_acc:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k5AZkvIZmqDX",
        "outputId": "938e1469-0618-49f0-e5af-e1ed2fdc17c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧠 Running SMART PROGRESSIVE SEARCH\n",
            "Running hyperparameter search with 3 configurations...\n",
            "\n",
            "🔍 Experiment 1/3\n",
            "\n",
            "==================================================\n",
            "Training with config: {'learning_rate': 0.001, 'mamba_d_state': 16, 'dropout_rate': 0.2, 'batch_size': 64, 'hidden_size': 128, 'conv_channels': [4, 4], 'weight_decay': 0.0001}\n",
            "==================================================\n",
            "Epoch  1: Train Acc: 0.5422 | Val Acc: 0.5870 | Loss: 327.1534\n",
            "Epoch  2: Train Acc: 0.5993 | Val Acc: 0.6122 | Loss: 304.2261\n",
            "Epoch  3: Train Acc: 0.6209 | Val Acc: 0.6243 | Loss: 296.4023\n",
            "Epoch  4: Train Acc: 0.6359 | Val Acc: 0.6243 | Loss: 290.0640\n",
            "Epoch  5: Train Acc: 0.6507 | Val Acc: 0.5969 | Loss: 284.0278\n",
            "Epoch  6: Train Acc: 0.6680 | Val Acc: 0.6235 | Loss: 277.0415\n",
            "Epoch  7: Train Acc: 0.6884 | Val Acc: 0.6287 | Loss: 267.9443\n",
            "Epoch  8: Train Acc: 0.7089 | Val Acc: 0.6062 | Loss: 255.5249\n",
            "Epoch  9: Train Acc: 0.7406 | Val Acc: 0.6070 | Loss: 239.0148\n",
            "Epoch 10: Train Acc: 0.7624 | Val Acc: 0.6010 | Loss: 221.0621\n",
            "Epoch 11: Train Acc: 0.8011 | Val Acc: 0.5908 | Loss: 197.3134\n",
            "Epoch 12: Train Acc: 0.8531 | Val Acc: 0.5845 | Loss: 155.9926\n",
            "Epoch 13: Train Acc: 0.8777 | Val Acc: 0.5873 | Loss: 132.4357\n",
            "Epoch 14: Train Acc: 0.8977 | Val Acc: 0.5791 | Loss: 115.7880\n",
            "Early stopping at epoch 14\n",
            "✅ Results: Val Acc: 0.6287 | Test Acc: 0.6073\n",
            "✅ Completed experiment 1 | Val Acc: 0.6287 | Best so far: 0.6388\n",
            "📁 Results saved to eeg_hyperparameter_results_fixed\n",
            "\n",
            "🔍 Experiment 2/3\n",
            "\n",
            "==================================================\n",
            "Training with config: {'learning_rate': 0.0005, 'mamba_d_state': 16, 'dropout_rate': 0.25, 'batch_size': 32, 'hidden_size': 128, 'conv_channels': [6, 6], 'weight_decay': 0.0001}\n",
            "==================================================\n",
            "Epoch  1: Train Acc: 0.5609 | Val Acc: 0.6010 | Loss: 640.5316\n",
            "Epoch  2: Train Acc: 0.6120 | Val Acc: 0.6169 | Loss: 599.5400\n",
            "Epoch  3: Train Acc: 0.6306 | Val Acc: 0.6257 | Loss: 585.8876\n",
            "Epoch  4: Train Acc: 0.6394 | Val Acc: 0.6399 | Loss: 576.4597\n",
            "Epoch  5: Train Acc: 0.6511 | Val Acc: 0.6437 | Loss: 567.8806\n",
            "Epoch  6: Train Acc: 0.6621 | Val Acc: 0.6366 | Loss: 558.6915\n",
            "Epoch  7: Train Acc: 0.6735 | Val Acc: 0.6336 | Loss: 545.8092\n",
            "Epoch  8: Train Acc: 0.6939 | Val Acc: 0.6344 | Loss: 528.2389\n",
            "Epoch  9: Train Acc: 0.7151 | Val Acc: 0.6262 | Loss: 505.7606\n",
            "Epoch 10: Train Acc: 0.7546 | Val Acc: 0.6188 | Loss: 456.8910\n",
            "Epoch 11: Train Acc: 0.7771 | Val Acc: 0.6213 | Loss: 424.1813\n",
            "Epoch 12: Train Acc: 0.8016 | Val Acc: 0.6141 | Loss: 395.0339\n",
            "Early stopping at epoch 12\n",
            "✅ Results: Val Acc: 0.6437 | Test Acc: 0.6298\n",
            "✅ Completed experiment 2 | Val Acc: 0.6437 | Best so far: 0.6437\n",
            "📁 Results saved to eeg_hyperparameter_results_fixed\n",
            "\n",
            "🔍 Experiment 3/3\n",
            "\n",
            "==================================================\n",
            "Training with config: {'learning_rate': 0.002, 'mamba_d_state': 8, 'dropout_rate': 0.1, 'batch_size': 64, 'hidden_size': 256, 'conv_channels': [4, 4], 'weight_decay': 0.001}\n",
            "==================================================\n",
            "Epoch  1: Train Acc: 0.5339 | Val Acc: 0.5670 | Loss: 345.9713\n",
            "Epoch  2: Train Acc: 0.5872 | Val Acc: 0.5980 | Loss: 307.1371\n",
            "Epoch  3: Train Acc: 0.5999 | Val Acc: 0.5969 | Loss: 301.0048\n",
            "Epoch  4: Train Acc: 0.6112 | Val Acc: 0.5993 | Loss: 297.8914\n",
            "Epoch  5: Train Acc: 0.6183 | Val Acc: 0.5977 | Loss: 295.6584\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-1319447725>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Step 1: Test a few promising configs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msafe_configs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_safe_search_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_configs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mbest_safe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-1141126697>\u001b[0m in \u001b[0;36mrun_search\u001b[0;34m(self, search_configs, max_experiments, random_search)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0;31m# Train with this configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_single_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;31m# Store results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-1141126697>\u001b[0m in \u001b[0;36mtrain_single_config\u001b[0;34m(self, config, max_epochs)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"classification\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-1141126697>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mode)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# Spatial path: process along time dimension (100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mx_svar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshared_mamba_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmamba_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedforward_2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch, 55, 100]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mx_savg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshared_mamba_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmamba_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedforward_2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch, 55, 100]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mx_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_svar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_savg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch, 55, 200]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-1141126697>\u001b[0m in \u001b[0;36mshared_mamba_block\u001b[0;34m(x, mamba, norm, feedforward)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mres1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmamba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mres1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mres2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mamba_ssm/modules/mamba_simple.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, inference_params)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0mconv_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_conv\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update state (B D W)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcausal_conv1d_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mseqlen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"silu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"swish\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             )\n\u001b[0;32m--> 370\u001b[0;31m         return F.conv1d(\n\u001b[0m\u001b[1;32m    371\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}